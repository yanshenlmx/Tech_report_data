---
title: "Technical Report: Full House Model in R"
author: "Shen Yan, Adrian Burgos Jr., Christopher Kinson, Brandon Niedert, and Daniel J. Eck"
date: "01/31/2022"
output:
  html_document:
    toc: true
    theme: united
---

# Introduction

We will go through an example of how our Full House Model era-adjusts batting averages (BA) using the parametric method, and bWAR(Baseball-Reference Win Above Replacement), fWAR(Fangraphs Win Above Replacement), HR(Home Run), BB(Walks) for batters, bWAR, fWAR, ERA(Earned Run Average), SO(Strikeout) for pitchers using the nonparametric method. We first load in relevant software packages and the data. Each row of data consists of a player ID.

The necessary data are collected from [Baseball-Reference](https://www.baseball-reference.com/), [Fangraphs](https://www.fangraphs.com/) and Github [Chadwick](https://github.com/chadwickbureau). The details of data collection are in the Supplement Materials.

[Baseball-Reference](https://www.baseball-reference.com/), a year ID, a park-factored BA, a era-adjusted at bats(adj_AB), a recorded number of at bats (AB), game(G), plate appearances (PA), and baseball-reference WAR(bWAR) and a value pops (the size of the MLB-eligible population in year i). The era-adjusted at bats(adj_AB) is computed based on the formula in the paper and the other variables are irrelevant for this analysis.

```{r message=FALSE}
rm(list=ls())
library(tidyverse)
library(orderstats)
library(Pareto)
library(parallel)
library(doParallel)
library(xtable)
years <- 1871:2021
ncores <- detectCores() - 1

## batters_AB.csv is part of the batters_all.csv and 
## contains the adjusted-AB that from 
## adjusted-AB = mapped-PA - adjusted-BB - HBP - SH - SF

batters <- read_csv("batters_AB.csv")[,-1]
```

In this analysis we will assume that batting averages (BA) $\stackrel{i i d}{\sim} N\left(\mu_{i}, \sigma_{i}\right)$ and that aptitude $\sim \operatorname{Pareto}(\alpha)$ where $\alpha=1.16$. We do not have any assumptions on the distribution of bWAR. This choice of alpha corresponds to the Pareto principle which is casually referred to as the $80 / 20$ rule.

# Parametric distribution measuring components

## BA

In this section, our Full House Model era-adjusts batting averages (BA) using the parametric distribution measuring the BA. We first declare a threshold for a batter to be considered a full-time batter. We choose the median PAs after screening out individuals who batted fewer than 75 PAs as our cutoff for full-time batters.

```{r}
cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))
batters <- merge(batters, cutoff, by = 'yearID')
batters <- batters %>% mutate(comp = AVG)
```

The code below introduces the function that transport normally distributed statistics to their talent scores.

```{r }
talent_computing_para <- function(dataset, year, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Aptitude_para <- function(y, mean = 0, sd = 1, alpha = 1.16, npop){
    
    # converts normal order stats to their percentiles
    order_pnorm <- function(q = 0, mean = 0, sd = 1, k = 1, n = 1e4){
      p <- pnorm(q, mean = mean, sd = sd)
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of normal order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    q <- sort(y) # just in case
    n <- length(y)
    u = unlist(lapply(1:n, function(j){
      order_pnorm(y[j], k = j, n = n, mean = mean, sd = sd)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qPareto(qbeta(u[j], j + npop[j]-n, n + 1 - j), t = 1, alpha = alpha)
    }))
  }
  
  # consider the full time batters
  foo <- dataset %>% filter(yearID == year) %>% arrange(comp)
  ## average talent
  bar <- foo %>% filter(PA >= thres)
  nsys <- nrow(bar)
  mu_comp <- mean(bar$comp)
  sd_comp <- sd(bar$comp)
  # components to build the CDF using parametric distribution
  bar <- bar %>% mutate(talent = 
                          Aptitude_para(comp, mean = mu_comp, sd = sd_comp, npop = pops))
  max_talent <- max(bar$talent) - 1
  # consider the non-full time batters
  non_full <- foo %>% filter(PA < thres)
  bar <- rbind(bar, do.call(rbind, lapply(1:nrow(non_full), function(j){
    m <- rbind(bar %>% dplyr::select(-talent), non_full[j, ]) %>% arrange(comp)
      m %>% mutate(talent = Aptitude_para(comp, mean = mu_comp, sd = sd_comp, npop = pops)) %>%
      filter(PA < thres) %>% 
      mutate(talent = ifelse(talent > max_talent+1, max_talent, talent))
  })))
  bar  
}
```

The following script computes the talent scores for BA from all batters and all years(1871 to 2021).

```{r cache = TRUE}
batters_talent_AVG <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_para(dataset = batters, year = yy)
})) %>% arrange(-talent)
```

From here we obtain the top seasons ever according to era-adjusted batting average. The last column displays the talent scores corresponding to these seasons. These talent scores do not have any tangible meaning beyond this (the first score is not roughly 3 times better than the second score).

```{r}
## top 25 average talent-scores
top25seasons_AVG <- (batters_talent_AVG %>% filter(PA >= thres) %>% arrange(-talent))[1:25, ]
## top 25 all-time batting seasons by talent-scores
m <- top25seasons_AVG %>% select(name, talent)
rownames(m) <- c()
```

We now take the above talent scores and reverse engineer the process to extract what these players who achieve if these seasons were to take place in 2021. To do this we first introduces the function that transport their talent scores to the context of the 2021 season and estimate the era-adjusted BA in 2021.

```{r}
Rev_Aptitude_para <- function(x, mean = 0, sd = 1, alpha = 1.16, npop){
  
  # transforms ordered Pareto values corresponding to 
  # the general population to percentiles from order stats 
  # (in increasing order)
  n <- length(x)
  if(length(npop) == 1) npop <- rep(npop, n)  
  u = unlist(lapply(1:n, function(j){
    pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
  }))
  
  # take the ordered percentiles and convert them to order statistics 
  # from a normal distribution
  n <- length(u)
  qnorm(qbeta(u, shape1 = 1:n, shape2 = n:1), mean = mean, sd = sd)
  
}
```

The code below finishes the task and places the above talent scores within the context of the 2021 season and outputs their corresponding 2021 batting averages.

```{r}
# first estimate normal distribution parameters for the 2021 season
ref_2021 <- batters_talent_AVG %>% filter(yearID == 2021) %>% filter(PA >= thres) 
mean_AVG_2021 <- mean(ref_2021$AVG)
sd_AVG_2021 <- sd(ref_2021$AVG)
w_pops_2021 <- unique(ref_2021$pops)

# compute the era-adjusted BA in 2021 for top 25 BA leaders
top25seasons_2021_AVG <- do.call(rbind, mclapply(1:25, mc.cores = ncores, function(j){ 
  xx <- top25seasons_AVG[j, ] 
xx$pops <- w_pops_2021
xx$playerID <- paste(xx$playerID, "_proj", sep = "")
int <- rbind(ref_2021, xx) %>% arrange(talent) %>% 
  mutate(adj_AVG = Rev_Aptitude_para(talent, mean = mean_AVG_2021, 
                                     sd = sd_AVG_2021, npop = w_pops_2021)) 
int[grepl("_proj", int$playerID), ]
})) 
n <- top25seasons_2021_AVG %>% select(name, talent, adj_AVG)
rownames(n) <- c()
```

We now extend the method to compute hypothetical careers in which we suppose that every player starts their career all at 1977. The reason we select 1977 season is the top 25 ranking list is stable when players start their career at this season.

```{r cache=TRUE}
foo <- batters_talent_AVG
foo$playerID <- droplevels(as.factor(foo$playerID))

# function that computes adjusted career averages over the hypothetical year
career_talent <- function(dataset, snippet, start_year){
  
  Rev_Aptitude_para <- function(x, mean = 0, sd = 1, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    # take the ordered percentiles and convert them to order statistics 
    # from a normal distribution
    n <- length(u)
    qnorm(qbeta(u, shape1 = 1:n, shape2 = n:1), mean = mean, sd = sd)
    
  }
  
  min_year <- min(snippet$yearID)
  max_year <- max(snippet$yearID)
  end_year <- max_year - min_year + start_year
  end_year <- ifelse(end_year <= 2021, end_year, 2021)
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(start_year : end_year, function(xx){
    batters_int <- dataset %>% filter(yearID == xx, PA >= thres)
    
    min_int <- min(batters_int$comp)
    mean_int <- mean(batters_int$comp)
    sd_int <- sd(batters_int$comp)
    
    target_snippet <- snippet %>% filter(yearID == (xx - start_year + min_year))
    
    batters_int <- rbind(batters_int, target_snippet)
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(talent) %>% 
      mutate(adj_AVG = Rev_Aptitude_para(talent, mean = mean_int, sd = sd_int, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    batters_int$adj_AVG <- ifelse(batters_int$adj_AVG < min_int, min_int, batters_int$adj_AVG)
    batters_int %>% mutate(ref_year = xx)
  }))
  
} 

## career start at 1977
ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
  int <- career_talent(dataset = foo,
                       snippet = foo %>% filter(playerID == zz),
                       start_year = ss)
  int
}, mc.cores = ncores)) 
 

```

After getting the era-adjusted BA, we find some players' BAs dramatically change in tails of their career, which is unrealistic in the real life. To solve it, we apply some smoothing methods to alleviate these dramatic variations, such as local polynomial regression fitting and natural cubic spline. Then natural cubic spline method has the minimal bias and is considered as the best option compared with other methods.

Also, we notice that the smoothing method could weaken player's prime or extreme seasons. Therefore, we take the average of the smoothed BA and era-adjusted BA, which can keep player's prime season and alleviate the dramatic changes in the tail of their career. The code below finishes the smoothing task and compute the career total BA for the players with at least 3000 ABs.

```{r cache=TRUE}
library(splines)
smoothed_AVG <- do.call(rbind, mclapply(split(career_kAB, f = droplevels(as.factor(career_kAB$playerID))), mc.cores = ncores, FUN = function(xx){
  ## smoothing spline
  ns_AVG = lm(adj_AVG ~ ns(yearID, df=6), data=xx)
  nn_AVG <- predict(ns_AVG, data.frame("yearID"= xx$yearID))
  xx %>% mutate(ss_adj_AVG = nn_AVG) %>% 
    mutate(avg_AVG = (ss_adj_AVG + adj_AVG)/2)
  }))

career_totals_AVG <- do.call(rbind, mclapply(
  split(smoothed_AVG, f = droplevels(as.factor(smoothed_AVG$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    xx <- xx %>% 
      mutate(adj_AVG = ifelse(adj_AVG < 0 , 0, adj_AVG))
    xx <- xx %>% mutate(adj_H = adj_AVG * adj_AB) 
    data.frame(playerID = unique(xx$playerID), name = unique(xx$name), rookie_year = min(xx$yearID), 
               AVG = sum(xx$AVG * xx$AB) / sum(xx$AB),
               avg_AVG = sum(xx$avg_AVG * xx$adj_AB) / sum(xx$adj_AB), AB = sum(xx$AB), adj_AB = sum(xx$adj_AB), adj_hit = sum(xx$adj_H), avg_hit = sum(xx$avg_AVG * xx$adj_AB))
  })) %>% arrange(-avg_AVG)

rownames(career_totals_AVG) <- c()
p <- (career_totals_AVG %>% filter(adj_AB >= 3000) %>% 
        select(name, rookie_year, avg_AVG))[1:25,]
```

### Figure 1: 4 moments of BA in Supplementary Materials

```{r cache=TRUE}
batters_AB <- smoothed_AVG  %>% 
  mutate(playerID = gsub('.{5}$', '', playerID)) %>% 
  select(yearID, chadID, playerID, fID, name, AB, PA, AVG, mapped_PA, adj_AB)

batters <- merge(batters_AB, cutoff, by = 'yearID') %>% filter(PA >= thres)

library(moments)
years = c(1871:2021)
mom1st <- sapply(years, function(x) mean(batters %>% 
                                           filter(yearID == x) %>%
                                           pull(AVG)))
mom2nd <- sapply(years, function(x) sd(batters %>% 
                                           filter(yearID == x) %>%
                                           pull(AVG)))
mom3rd <- sapply(years, function(x) skewness(batters %>% 
                                         filter(yearID == x) %>%
                                         pull(AVG)))
mom4th <- sapply(years, function(x) kurtosis(batters %>% 
                                               filter(yearID == x) %>%
                                               pull(AVG)))

par(mfrow = c(2,2), oma = c(4,4,1,0), mar = c(1,2,1,1))
plot.new()
title('mean of batting averages')
plot.window(xlim = c(1871,2021), ylim = c(0.25,0.32))
points(years[-c(71:76)], mom1st[-c(71:76)], pch = 19)
points(years[c(71:76)], mom1st[c(71:76)], pch = 19, col = 'red')
axis(2)
plot.new()
title('sd of batting averages')
plot.window(xlim = c(1871,2021), ylim = c(0.02, 0.06))
points(years[-c(71:76)], mom2nd[-c(71:76)], pch = 19)
points(years[c(71:76)], mom2nd[c(71:76)], pch = 19, col = 'red')
axis(2)
plot.new()
title('skewness of batting averages')
plot.window(xlim = c(1871,2021), ylim = c(-0.46,0.98))
points(years[-c(71:76)], mom3rd[-c(71:76)], pch = 19)
points(years[c(71:76)], mom3rd[c(71:76)], pch = 19, col = 'red')
axis(1, xaxp=c(1870, 2020, 15), las=1)
axis(2)
plot.new()
title('kurtosis of batting averages')
plot.window(xlim = c(1871,2021), ylim = c(1.78,4.57))
points(years[-c(71:76)], mom4th[-c(71:76)], pch = 19)
points(years[c(71:76)], mom4th[c(71:76)], pch = 19, col = 'red')
axis(1, xaxp=c(1870, 2020, 15), las=1)
axis(2)

```

# Nonarametric distribution measuring components

## batters

### bWAR

In this section, our Full House Model era-adjusts bWAR using the nonparametric distribution measuring the bWAR. The code below introduces the two functions: the first one establishes the interpolated empirical CDF $\widetilde{F}_{Y_i}$ mentioned in the paper; the second one transport statistics with unknown distribution to their talent scores

```{r}
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}
```

```{r}
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qPareto(qbeta(u[j], j + npop[j] -n , n + 1 - j), t = 1, alpha = alpha)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(PA >= thres)
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(PA < thres) %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

```

We now try out the bWAR for batters and first we select the full-time batteres. Same as what we do in parametric part, We declare the median PAs after screening out individuals who batted fewer than 75 PAs as our cutoff for full-time batters.

```{r message=FALSE}
batters <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, age, PA, G, bWAR,pops)
colnames(batters)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters, cutoff, by = 'yearID')
```

We use bWAR per game as the components in the system to compute the talent score corresponding to bWAR.

```{r}
batters <- batters %>% mutate(comp =  bWAR / G)
```

The following function is to calculate the $Y_i^{**}$ based on the optimization problem from the paper.

```{r}
bat_thres <- function(component, component_name){
  ## stab means we add a small number to the largest value to avoid numerical stability problems. 
  ## stab depends on the scale of input values. In most cases, the default is 0.01. 
  ## cutoff means we select a certain percentage of systems that include maximal possible components in the tail
  ## rather than include k possible components in the tail based on the adjusted R adjusted square. 
  ## If the distance between the largest value and second largest value in the right tail is relatively large,
  ## adjusted R square may not be a good quantity to represent how well the fit is. 
  ## Then we usually choose the one sixth of all systems that their distances between the largest value and 
  ## second largest value are in the top one sixth. 
  
  if (component_name == 'bWAR') {
    cutoff <- 1.6e-2
    stab <- 0.01
  }
  if (component_name == 'fWAR') {
    cutoff <- 1.75e-2
    stab <- 0.01
  }
  if (component_name == 'HR') {
    cutoff <- 2.06e-2
    stab <- 0.01
  }
  if (component_name == 'BB') {
    cutoff <- 4.05e-2
    stab <- 0.027
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar

}

```

The following script computes the talent scores for bWAR per game from all batters and all years(1871 to 2021).

```{r cache=TRUE}

batters_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "bWAR", year = yy, ystar = bat_thres(component = batters %>% filter(PA >= thres, yearID == yy) %>% select(comp), component_name = 'bWAR')) })) %>% arrange(-WAR_talent)
```

We now take the above talent scores and reverse engineer the process to extract what these players who achieve if the players start their career at 1977. To do this we first introduces the function that transport their talent scores to the context of the seasons start at 1977 and estimate the era-adjusted bWAR per game.

```{r}
career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  min_year <- min(snippet$yearID)
  max_year <- max(snippet$yearID)
  end_year <- max_year - min_year + start_year
  end_year <- ifelse(end_year <= 2021, end_year, 2021)
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(start_year : end_year, function(xx){
    batters_int <- dataset %>% filter(yearID == xx, PA >= thres)
    
    target_snippet <- snippet %>% filter(yearID == (xx - start_year + min_year))
    yy <- sort(batters_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, target_snippet)
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    batters_int %>% mutate(ref_year = xx)
  }))
  
} 
```

The codes below compute hypothetical careers in which we suppose that every player all start their career at 1977.

```{r cache=TRUE}

foo <- batters_talent_bWAR
foo$playerID <- droplevels(as.factor(foo$playerID))

# get career adjustment on season by season basis
ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
  int <- career_talent(dataset = foo, component_name = 'bWAR', 
                       snippet = foo %>% filter(playerID == zz), 
                       start_year = ss)
  int
}, mc.cores = ncores)) 


```

Instead of using the raw games in the data set, we calculate the mapped games by applying quantile mapping for the full-time hitters and non-full-time hitters separately. Quantile mapping is based on that a pth percentile player's games in one year is equal to a pth percentile player's games in another year.

We will assume that worst performance in the full time players in each season are considered as the worst performance for all players in that season.

```{r cache=TRUE}
mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

career_kAB <- career_kAB %>% mutate(playerID = gsub('.{5}$', '', playerID))

mapped_batters_1 <- merge(career_kAB, mapped_quan_b, 
                          by = c('playerID', 'yearID', 'ref_year'))

mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                          by = c('ref_year'))

mapped_batters_3 <- mapped_batters_2 %>% mutate(adj_bWAR = adj_comp * mapped_G)

min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
  data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
}, mc.cores = ncores)) 

mapped_batters <- merge(mapped_batters_3, min_refbWAR, 
                        by = c('ref_year'))
```

We trim careers when era-adjusted bWAR falls below replacement level for an extended period of time. The players will be removed from the league if their bad-performances last for a long time. The code below shows that how we trim the players when they display below replacement level.

```{r cache=TRUE}

career_kAB_trim <- do.call(rbind, mclapply(
  split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    zz <- xx %>% filter(PA < thres) %>% 
      mutate(adj_bWAR = (1 - mapped_PA/PA_thres) * bWAR + mapped_PA/PA_thres * (adj_bWAR))
    tt <- xx %>% filter(PA >= thres)
    xx <- rbind(zz, tt) %>% arrange(yearID)
    
    m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
      mutate(adj_bWAR = min_bWAR) %>%
      mutate(mapped_G = adj_bWAR / adj_comp)
    m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
    rbind(m1, m2) %>% arrange(yearID)
    
  }))

career_kAB_trim_select <- career_kAB_trim 

```

We apply the smoothing method from the parametric part to the era-adjusted bWAR.

```{r cache=TRUE}

library(splines)
smoothed_bWAR <- do.call(rbind, mclapply(
  split(career_kAB_trim_select, 
        f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
    nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
    xx %>% mutate(ss_adj_bWAR = nn_bWAR) %>% 
      mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
  })) 

career_bWAR <- smoothed_bWAR %>% group_by(playerID) %>% 
  summarise(name = unique(name), playerID = unique(playerID), rookie_year = min(yearID), 
            avg_bWAR = sum(avg_bWAR), bWAR = sum(bWAR), span = n()) %>%
  arrange(desc(avg_bWAR)) %>% ungroup()
rownames(career_bWAR) <- c()
```

We will repeat the same processes to the remaining baseball statistics: such as fWAR for batters, Home Run, bWAR and fWAR for pitchers, ERA and SO.

### fWAR

```{r message=FALSE}
batters <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, PA, G, fWAR,pops)
colnames(batters)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters, cutoff, by = 'yearID')
batters <- batters %>% mutate(comp =  fWAR / G)
```

```{r cache=TRUE}
batters_talent_fWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "fWAR", 
                           year = yy, ystar = bat_thres(component = batters %>% 
                                                          filter(PA >= thres, yearID == yy) %>% 
                                                          select(comp), component_name = 'fWAR'))
})) %>% arrange(-WAR_talent)

```

```{r cache=TRUE}
foo <- batters_talent_fWAR
foo$playerID <- droplevels(as.factor(foo$playerID))

# get career adjustment on season by season basis
ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
  int <- career_talent(dataset = foo, component_name = 'fWAR', 
                       snippet = foo %>% filter(playerID == zz), 
                       start_year = ss)
  int
}, mc.cores = ncores))  

```

```{r cache=TRUE}
mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

career_kAB <- career_kAB %>% mutate(playerID = gsub('.{5}$', '', playerID))

mapped_batters_1 <- merge(career_kAB, mapped_quan_b, 
                          by = c('playerID', 'yearID', 'ref_year'))

mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                          by = c('ref_year'))

mapped_batters_3 <- mapped_batters_2 %>% mutate(adj_fWAR = adj_comp * mapped_G)

min_reffWAR <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
  data.frame(ref_year = zz, min_fWAR = min(m$fWAR))
}, mc.cores = ncores)) 

mapped_batters <- merge(mapped_batters_3, min_reffWAR, 
                        by = c('ref_year'))
```

```{r cache=TRUE}
career_kAB_trim <- do.call(rbind, mclapply(
  split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    zz <- xx %>% filter(PA < thres) %>% 
      mutate(adj_fWAR = (1 - mapped_PA/PA_thres) * fWAR + mapped_PA/PA_thres * (adj_fWAR))
    tt <- xx %>% filter(PA >= thres)
    xx <- rbind(zz, tt) %>% arrange(yearID)
    
    m1 <- xx %>% filter(adj_fWAR < min_fWAR) %>% 
      mutate(adj_fWAR = min_fWAR) %>%
      mutate(mapped_G = adj_fWAR / adj_comp)
    m2 <- xx %>% filter(adj_fWAR >= min_fWAR)
    rbind(m1, m2) %>% arrange(yearID)
    
  }))

career_kAB_trim_select <- career_kAB_trim %>% 
  select(name, playerID, yearID, adj_fWAR, fWAR, ref_year)

library(splines)
smoothed_fWAR <- do.call(rbind, mclapply(
  split(career_kAB_trim_select, 
        f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_fWAR = lm(adj_fWAR ~ ns(yearID, df=6), data=xx)
    nn_fWAR <- predict(ns_fWAR, data.frame("yearID"= xx$yearID))
    xx %>% mutate(ss_adj_fWAR = nn_fWAR) %>% 
      mutate(avg_fWAR = (ss_adj_fWAR + adj_fWAR)/2)
  })) 

career_fWAR <- smoothed_fWAR %>% group_by(playerID) %>% 
  summarise(name = unique(name), playerID = unique(playerID), rookie_year = min(yearID), 
            avg_fWAR = sum(avg_fWAR), fWAR = sum(fWAR), span = n()) %>%
  arrange(desc(avg_fWAR)) %>% ungroup()

rownames(career_fWAR) <- c()
```

### Figure 2: year effect of bWAR and fWAR in the paper

```{r cache=TRUE}

# bWAR

ref_2021 <- batters_talent_bWAR %>% filter(yearID == 2021) %>% filter(PA >= thres) %>% 
  select(yearID, playerID, PA, comp, pops, thres)
fake_player <- data.frame(yearID = 2021, playerID = "fake01", PA = 315, comp = 0, 
                          pops = unique(ref_2021$pops), thres = 315 )
ref_2021 <- rbind(ref_2021, fake_player)
bar <- ref_2021 %>% arrange(comp)

## batter WAR talent

talent_2021 <- talent_computing_nonpara(dataset = bar, component_name = "bWAR", year = 2021, ystar = bat_thres(component = bar %>% select(comp), component_name = 'bWAR'))

foo <- batters_talent_bWAR %>% 
  select(yearID, playerID, PA, comp, pops, thres, WAR_talent, ystar)

career_talent_0 <- function(snippet, target_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(snippet$yearID, function(xx){
    batters_int <- foo %>% filter(yearID == target_year) %>% filter(PA >= thres)
    
    if (target_year == 2021) {
      yy = sort(ref_2021$comp)
    } else {
      yy <- sort(batters_int$comp)
    }
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    ytilde[1] <- yy[1] - (yy[2] - yy[1])
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, snippet %>% filter(yearID == xx))
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    batters_int
  })) %>% mutate(ref_year = target_year)
}

adj_0_bWAR <- do.call(rbind, mclapply(1871:2021, function(xx){
  int <- career_talent_0(snippet = talent_2021 %>% filter(playerID == 'fake01'), target_year = xx) 
  int
}, mc.cores = ncores))

## quantile mapping
m <- mapped_batters_1 %>% filter(PA >= thres) %>% select(yearID, G, mapped_G)

adj_season_G <- do.call(rbind, mclapply(1871:2021, function(xx){
  s <- m %>% filter(yearID == xx)
  c(ref_year = xx, mapped_G = approx(s$mapped_G, s$G, xout = 120)$y)
}, mc.cores = ncores))  

adj_0_bWAR_G <- merge(adj_0_bWAR, adj_season_G, by = c('ref_year'))

adj_0_bWAR_G <- adj_0_bWAR_G %>% mutate(adj_bWAR = adj_comp * mapped_G)

```

```{r cache=TRUE}

# fWAR

ref_2021 <- batters_talent_fWAR %>% filter(yearID == 2021) %>% filter(PA >= thres) %>% 
  select(yearID, playerID, PA, comp, pops, thres)
fake_player <- data.frame(yearID = 2021, playerID = "fake01", PA = 315, comp = 1e-10, 
                          pops = unique(ref_2021$pops), thres = 315 )
ref_2021 <- rbind(ref_2021, fake_player)
bar <- ref_2021 %>% arrange(comp)

## batter WAR talent

talent_2021 <- talent_computing_nonpara(dataset = bar, component_name = "fWAR", year = 2021, ystar = bat_thres(component = bar %>% select(comp), component_name = 'fWAR'))

foo <- batters_talent_fWAR %>% 
  select(yearID, playerID, PA, comp, pops, thres, WAR_talent, ystar)

career_talent_0 <- function(snippet, target_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(snippet$yearID, function(xx){
    batters_int <- foo %>% filter(yearID == target_year) %>% filter(PA >= thres)
    
    if (target_year == 2021) {
      yy = sort(ref_2021$comp)
    } else {
      yy <- sort(batters_int$comp)
    }
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    ytilde[1] <- yy[1] - (yy[2] - yy[1])
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, snippet %>% filter(yearID == xx))
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    batters_int
  })) %>% mutate(ref_year = target_year)
}

adj_0_fWAR <- do.call(rbind, mclapply(1871:2021, function(xx){
  int <- career_talent_0(snippet = talent_2021 %>% filter(playerID == 'fake01'), target_year = xx) 
  int
}, mc.cores = ncores))

## quantile mapping
m <- mapped_batters_1 %>% filter(PA >= thres) %>% select(yearID, G, mapped_G)

adj_season_G <- do.call(rbind, mclapply(1871:2021, function(xx){
  s <- m %>% filter(yearID == xx)
  c(ref_year = xx, mapped_G = approx(s$mapped_G, s$G, xout = 113)$y)
}, mc.cores = ncores))  

adj_0_fWAR_G <- merge(adj_0_fWAR, adj_season_G, by = c('ref_year'))

adj_0_fWAR_G <- adj_0_fWAR_G %>% mutate(adj_fWAR = adj_comp * mapped_G)
```

```{r}
year = c(1871:2021)[-150]
plot(year, (adj_0_bWAR_G$adj_comp * adj_0_bWAR_G$mapped_G)[-150], 
     type = 'l', col="black", ylab="", bty = 'n', xaxt="n")
axis(1, xaxp=c(1870, 2020, 15), las=1)
lines(year, (adj_0_fWAR_G$adj_comp * adj_0_fWAR_G$mapped_G)[-150], 
      col="red")
abline(h = 0, lty = 2)
legend('topright', legend = c('bWAR', 'fWAR'), 
       col = c('black','red'), lty = 1, bty = 'n')

```

### HR

```{r message=FALSE}
batters_HR <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, PA, HR, HR_AB, BB, HBP, SH, SF, pops)
colnames(batters_HR)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters_HR %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters_HR, cutoff, by = 'yearID')

batters <- batters %>% mutate(comp =  HR_AB)
```

```{r cache=TRUE}
batters_talent_HR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "HR", 
                           year = yy, ystar = bat_thres(component = batters %>% 
                                                          filter(PA >= thres, yearID == yy) %>% 
                                                          select(comp), component_name = 'HR'))
})) %>% arrange(-WAR_talent)

```

```{r cache=TRUE}
foo <- batters_talent_HR
foo$playerID <- droplevels(as.factor(foo$playerID))

# get career adjustment on season by season basis
## career start at 1977
ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
  int <- career_talent(dataset = foo, component_name = 'HR', 
                       snippet = foo %>% filter(playerID == zz), 
                       start_year = ss)
  int
}, mc.cores = ncores)) 
```

### BB

```{r message=FALSE}
batters_BB <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, PA, BB, pops)
colnames(batters_BB)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters_BB %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters_BB, cutoff, by = 'yearID')
batters$PA[batters$PA == 0] <- 1
batters <- batters %>% mutate(comp = BB / PA)

```

```{r cache=TRUE}
batters_talent_BB <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "BB", 
                           year = yy, ystar = 
                             bat_thres(component = batters %>% 
                                         filter(PA >= thres, yearID == yy) %>% 
                                         select(comp), component_name = 'BB'))
})) %>% arrange(-WAR_talent)

```

```{r cache=TRUE}
foo <- batters_talent_BB
foo$playerID <- droplevels(as.factor(foo$playerID))

# get career adjustment on season by season basis
ss = 1977

career_kAB_BB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
  int <- career_talent(dataset = foo, component_name = 'BB', 
                       snippet = foo %>% filter(playerID == zz), 
                       start_year = ss)
  int
}, mc.cores = ncores))  

```

```{r cache=TRUE}
mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

colnames(career_kAB)[16] <- 'adj_HR_AB'

career_combined <- merge(career_kAB %>% select(-comp), career_kAB_BB %>% 
                           select(yearID, playerID, comp, adj_comp), by = c('yearID', 'playerID'))

career_combined <- career_combined %>% mutate(playerID = gsub('.{5}$', '', playerID))

mapped_batters_1 <- merge(career_combined, mapped_quan_b, 
                          by = c('playerID', 'yearID', 'ref_year'))

mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                          by = c('ref_year'))

min_refBB <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_batters_2 %>% filter(yearID == zz, PA >= thres)
  data.frame(ref_year = zz, min_BB = min(m$BB))
}, mc.cores = ncores)) 

mapped_batters_3 <- merge(mapped_batters_2, min_refBB, 
                          by = c('ref_year'))

min_refHR <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
  data.frame(ref_year = zz, min_HR = min(m$HR))
}, mc.cores = ncores)) 

mapped_batters_4 <- merge(mapped_batters_3, min_refHR, 
                          by = c('ref_year'))


mapped_batters <- mapped_batters_4 %>%
  mutate(adj_BB = ceiling(adj_comp * ceiling(mapped_PA))) %>% 
  mutate(adj_BB = ifelse(adj_BB < min_BB, min_BB, adj_BB)) %>% 
  mutate(adj_AB = ceiling(mapped_PA) - adj_BB - HBP - SH - SF) %>% 
  mutate(adj_AB = ifelse(adj_AB <0, 0, adj_AB)) %>% 
  mutate(adj_HR = ceiling(adj_HR_AB * adj_AB)) %>% 
  mutate(adj_HR = ifelse(adj_HR < min_HR, min_HR, adj_HR)) 

```

```{r cache=TRUE}
career_kAB_trim <- do.call(rbind, mclapply(
  split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## weighted average for HR
    xx <- xx %>% arrange(yearID)
    zz <- xx %>% filter(mapped_PA < PA_thres) %>% 
      mutate(adj_HR = ceiling((1 - mapped_PA/PA_thres) * HR + 
                                mapped_PA/PA_thres * (adj_HR))) %>% 
      mutate(adj_BB = ceiling((1 - mapped_PA/PA_thres) * BB + 
                                mapped_PA/PA_thres * (adj_BB)))
    mm <- rbind(zz, xx %>% filter(mapped_PA >= PA_thres)) %>% arrange(yearID)
    mm
  }))

library(splines)
smoothed_BB <- do.call(rbind, mclapply(
  split(career_kAB_trim, f = droplevels(as.factor(career_kAB_trim$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_BB = lm(adj_BB ~ ns(yearID, df=6), data=xx)
    nn_BB <- predict(ns_BB, data.frame("yearID"= xx$yearID))
    xx %>% mutate(ss_adj_BB = round(nn_BB)) %>% 
      mutate(avg_BB = round((ss_adj_BB + adj_BB)/2))
  })) 

smoothed_HR <- do.call(rbind, mclapply(
  split(career_kAB_trim, f = droplevels(as.factor(career_kAB_trim$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_HR = lm(adj_HR_AB ~ ns(yearID, df=6), data=xx)
    nn_HR_AB <- predict(ns_HR, data.frame("yearID"= xx$yearID))
    nn_HR_AB <- ifelse(nn_HR_AB < 0, 0, nn_HR_AB)
    xx %>% mutate(ss_adj_HR_AB = nn_HR_AB) %>%
      mutate(avg_HR_AB = (adj_HR_AB + ss_adj_HR_AB)/2)
  })) 

smoothed_HR <- smoothed_HR %>% mutate(ss_adj_HR = ceiling(ss_adj_HR_AB * adj_AB)) %>%
  mutate(avg_HR = ceiling(avg_HR_AB * adj_AB))

career_BB <- smoothed_BB %>% group_by(playerID) %>% 
  summarise(name = unique(name), playerID = unique(playerID), rookie_year = min(yearID), 
            avg_BB = sum(avg_BB), BB = sum(BB), span = n()) %>%
  arrange(desc(avg_BB)) %>% ungroup()

career_HR <- smoothed_HR %>% group_by(playerID) %>% 
  summarise(name = unique(name), playerID = unique(playerID), rookie_year = min(yearID), 
            avg_HR = sum(avg_HR), HR = sum(HR), span = n()) %>%
  arrange(desc(avg_HR)) %>% ungroup()

rownames(career_BB) <- c()
rownames(career_HR) <- c()
```

### combined batting statistics

We combine all the era-adjusted batting statistics together.

```{r cache=TRUE}
smoothed_AVG <- smoothed_AVG %>% mutate(playerID = gsub('.{5}$', '', playerID))

AVG_part <- smoothed_AVG %>% mutate(AVG = round(AVG, 3)) %>% 
  mutate(adj_AVG = round(adj_AVG, 3)) %>%
  mutate(avg_AVG = round(avg_AVG, 3)) %>%
  mutate(obs_AVG = round(obs_AVG, 3)) %>%
  mutate(obs_hits = round(obs_hits)) %>%
  mutate(obs_HR = round(obs_HR)) %>%
  mutate(AB = round(AB)) %>%
  mutate(adj_AB = round(adj_AB)) %>%
  mutate(avg_hits = round(adj_AB * avg_AVG)) %>% 
  select(yearID, playerID, name, AB, adj_AB, obs_AVG, AVG, avg_AVG, obs_hits, avg_hits, obs_HR) 

```

```{r}
HR_part <- smoothed_HR %>% mutate(mapped_PA = round(mapped_PA)) %>%
  select(yearID, playerID, HR, avg_HR, HBP, SF, PA,mapped_PA) 
```

```{r}
bWAR_part <- smoothed_bWAR %>% mutate(bWAR = round(bWAR, 2)) %>%
  mutate(avg_bWAR = round(avg_bWAR, 2)) %>%
  select(yearID, playerID, age, G, mapped_G, bWAR, avg_bWAR, pops) 
```

```{r}
fWAR_part <- smoothed_fWAR %>% mutate(fWAR = round(fWAR, 2)) %>%
  mutate(avg_fWAR = round(avg_fWAR, 2)) %>%
  select(yearID, playerID, fWAR, avg_fWAR) 
```

```{r}
BB_part <- smoothed_BB %>% select(yearID, playerID, BB, adj_BB, avg_BB)
```

```{r}
master_batters <- merge(BB_part, merge(AVG_part, 
                                       merge(HR_part, merge(bWAR_part, fWAR_part, 
                                                            by = c('yearID', 'playerID')), 
                                             by = c('yearID', 'playerID')), 
                                       by = c('yearID', 'playerID')), 
                        by = c('yearID', 'playerID'))

master_batters <- master_batters %>% mutate(obs_OBP = (obs_hits + BB + HBP) / (AB + BB + HBP + SF)) %>%
  mutate(avg_OBP = (avg_AVG * adj_AB + avg_BB + HBP) / (adj_AB + avg_BB + HBP + SF))
master_batters$obs_OBP[is.na(master_batters$obs_OBP)] <- 0
master_batters$avg_OBP[is.na(master_batters$avg_OBP)] <- 0

master_batters <- master_batters %>% mutate(avg_BB = ifelse(avg_BB < 0, 0, avg_BB)) %>% 
  mutate(adj_AB = ifelse(mapped_PA < adj_AB, mapped_PA, adj_AB))
```

### final adjustment on batters

We extract and remove bad performance season in their career

```{r cache=TRUE}
batters <- master_batters %>% 
  mutate(adj_AB_HR = round(adj_AB/avg_HR, 1))
batters <- batters[batters$avg_bWAR != 0, ]

foo <- batters %>% 
  arrange(desc(avg_AVG)) %>% 
  filter(adj_AB >= 300) %>% 
  dplyr::select(name, playerID, yearID, adj_AB, avg_AVG, avg_OBP, avg_HR, avg_fWAR, avg_bWAR) %>% 
  mutate(adj_HR_AB = round(avg_HR/adj_AB,4))

bar <- split(foo, as.factor(foo$playerID))
baz <- do.call(rbind, lapply(bar, function(m){
  m[which.max(m$avg_fWAR), ]
}))
baz <- baz %>% arrange(avg_fWAR)
bad_players_fWAR <- baz %>% filter(avg_fWAR < 0) %>% pull(playerID)

baz <- do.call(rbind, lapply(bar, function(m){
  m[which.max(m$avg_bWAR), ]
}))
baz <- baz %>% arrange(avg_bWAR)
bad_players_bWAR <- baz %>% filter(avg_bWAR < 0) %>% pull(playerID)
bad_players <- union(bad_players_bWAR, bad_players_fWAR)
batters <- batters[!batters$playerID %in% bad_players, ]

###### investigate anomalies ######

## more on base events than PAs
# problem with the smoothing, revert to adjustment
batters[which(batters$avg_BB > batters$mapped_PA), ]$avg_BB <- 
  batters[which(batters$avg_BB > batters$mapped_PA), ]$adj_BB
batters[which(batters$avg_BB > batters$mapped_PA), ]$mapped_PA <- 
  batters[which(batters$avg_BB > batters$mapped_PA), ]$avg_BB

# taper down average WAR for players with small PAs
batters[batters$mapped_PA <= 20, ]$avg_fWAR <- 
  round(batters[batters$mapped_PA <= 20, ]$avg_fWAR/9,2)
batters[batters$mapped_PA <= 20, ]$avg_bWAR <- 
  round(batters[batters$mapped_PA <= 20, ]$avg_bWAR/9,2)	

# check average for minimal at bats and correct issues
batters[batters$avg_AVG > 0 & batters$adj_AB == 0, ]$avg_AVG <- 0 
batters <- batters %>% mutate(avg_hits = round(avg_AVG * adj_AB))
batters[batters$adj_AB > 0, ]$avg_AVG <- 
  round(batters[batters$adj_AB > 0, ]$avg_hits / batters[batters$adj_AB > 0, ]$adj_AB, 3)

# recalculate adjusted OBP
index <- batters$adj_AB + batters$avg_BB + batters$HBP + batters$SF > 0
batters[!index, ]$avg_OBP <- 0
batters[index, ]$avg_OBP <- 
  round((batters[index, ]$avg_hits + batters[index, ]$avg_BB + batters[index, ]$HBP)/
          (batters[index, ]$adj_AB + batters[index, ]$avg_BB + batters[index, ]$HBP + batters[index, ]$SF),3 )

# recalculate home runs
batters[batters$avg_HR > batters$adj_AB, ]$batters$avg_HR <- 
  batters[batters$avg_HR > batters$adj_AB, ]$batters$adj_AB
batters <- batters %>% 
  mutate(adj_AB_HR = round(adj_AB/avg_HR, 1))


## build adjusted data set
batters_adjusted <- batters %>% 
  dplyr::select(name, playerID, age, yearID, mapped_PA, adj_AB, avg_hits, avg_HR, avg_BB, 
                avg_AVG, avg_OBP, HBP, SF, avg_bWAR, avg_fWAR)
colnames(batters_adjusted) <- c("name", "playerID", "age", "year", "PA", "AB", "H", 
                                "HR", "BB", "AVG", "OBP", "HBP", "SF", "ebWAR", "efWAR")
batters_adjusted$playerID <- droplevels(as.factor(batters_adjusted$playerID))
batters_adjusted <- batters_adjusted[!is.na(batters_adjusted$age), ]


## trim out bad players
# first round
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
})
checker <- data.frame(pid = levels(batters_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
batters_adjusted <- batters_adjusted %>% 
  filter(!batters_adjusted$playerID %in% rownames(checker)[checker$m_bad == 2])
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

# second round
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
})
checker <- data.frame(pid = levels(batters_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
batters_adjusted <- batters_adjusted %>% 
  filter(!batters_adjusted$playerID %in% rownames(checker)[checker$m_bad >= 1 & checker$len <= 2])
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

# third round
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  min(ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0))
})
checker <- data.frame(pid = levels(batters_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
batters_adjusted <- batters_adjusted %>% 
  filter(!batters_adjusted$playerID %in% rownames(checker)[checker$m_bad >= 1])
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

## remove tails
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- sum(c(ifelse(sum(tail(bad, 2)) >= 3,1,0), 
                    ifelse(sum(tail(bad, 3)) >= 5,1,0), 
                    ifelse(sum(tail(bad, 4)) >= 7,1,0),
                    ifelse(sum(tail(bad, 5)) >= 9,1,0), 
                    ifelse(sum(tail(bad, 6)) >= 11,1,0)))
  c(length(bad), 1:(length(bad)-bad_tail))
  1:(length(bad)-bad_tail)
})
batters_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- c(ifelse(sum(tail(bad, 3)) >= 4,1,0), 
                ifelse(sum(tail(bad, 4)) >= 5,1,0), 
                ifelse(sum(tail(bad, 5)) >= 7,1,0), 
                ifelse(sum(tail(bad, 6)) >= 8,1,0), 
                ifelse(sum(tail(bad, 7)) >= 9,1,0),
                ifelse(sum(tail(bad, 8)) >= 10,1,0),
                ifelse(sum(tail(bad, 9)) >= 11,1,0))
  int <- 1:length(bad)
  if(any(bad_tail == 1)) int <- 1:(length(bad) - max(which(bad_tail == 1)))
  int
})
batters_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

## remove starts
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_head <- sum(c(ifelse(sum(head(bad, 2)) >= 3,1,0), 
                    ifelse(sum(head(bad, 3)) >= 5,1,0), 
                    ifelse(sum(head(bad, 4)) >= 7,1,0),
                    ifelse(sum(head(bad, 5)) >= 9,1,0), 
                    ifelse(sum(head(bad, 6)) >= 11,1,0)))
  (bad_head + 1):length(bad)
})
batters_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)

## remove tails (take 2)
foo <- split(batters_adjusted, f = batters_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- sum(c(ifelse(sum(tail(bad, 2)) >= 3,1,0), 
                    ifelse(sum(tail(bad, 3)) >= 5,1,0), 
                    ifelse(sum(tail(bad, 4)) >= 7,1,0),
                    ifelse(sum(tail(bad, 5)) >= 9,1,0), 
                    ifelse(sum(tail(bad, 6)) >= 11,1,0)))
  c(length(bad), 1:(length(bad)-bad_tail))
  1:(length(bad)-bad_tail)
})
batters_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
batters_adjusted$playerID <- droplevels(batters_adjusted$playerID)
career_batters <- batters_adjusted %>% group_by(playerID) %>% 
  summarise(name = unique(name), key_bbref = unique(playerID), 
            PA = sum(PA), AB = sum(AB), H = sum(H), 
            HR = sum(HR), BB = sum(BB), AVG = round(sum(H)/sum(AB),3), 
            OBP = round((sum(H) + sum(BB) + sum(HBP))/(sum(AB) + sum(BB) + sum(HBP) + sum(SF)),3), 
            ebWAR = round(sum(ebWAR),2), efWAR = round(sum(efWAR),2)) %>%
  arrange(desc(ebWAR)) %>% ungroup()

career_batters <- career_batters %>% 
  mutate(AVG = ifelse(is.na(AVG), 0, AVG)) %>% 
  mutate(OBP = ifelse(is.na(OBP), 0, OBP)) %>% 
  mutate(PA = ifelse(PA == 0, 1, PA)) %>%
  mutate(AB = ifelse(AB == 0, 1, AB))
```

```{r}
## BA ranking list
(career_batters %>% filter(AB >= 3000) %>% 
  arrange(desc(AVG)))[1:25,]

## OBP ranking list
(career_batters %>% filter(AB >= 3000) %>% 
  arrange(desc(OBP)))[1:25,]

## HR ranking list
(career_batters %>% 
  arrange(desc(HR)))[1:25,]

## bWAR ranking list
(career_batters %>% 
  arrange(desc(ebWAR)))[1:25,]

## fWAR ranking list
(career_batters %>% 
  arrange(desc(efWAR)))[1:25,]
```

## pitchers

We apply our Full House Model to the pitching statistics: bWAR, fWAR, ERA and SO.

### bWAR

```{r message=FALSE}
pitchers <- read_csv("pitchers_all.csv")[,-1]
pitchers <- pitchers %>% mutate(comp = bWAR / IP) 
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'
```

```{r cache=TRUE}
library(retrosheet)
rotation_bound <- as.data.frame(cbind(years, unlist(mclapply(years, mc.cores = ncores, function(yr){
  foo <- getRetrosheet(type = "game", year = yr)
  Tms <- unique(foo$HmTm)
  
  starter <- lapply(Tms, function(tm){
    bar <- foo %>% filter(VisTm == tm | HmTm == tm) %>% 
      select(VisTm, HmTm, VisStPchID, HmStPchID, VisTmGNum, HmTmGNum)
    t(apply(bar, 1, function(xx){
      y <- NULL
      if(xx[2] == tm){
        y <- xx[4]
      }
      else{
        y <- xx[3]
      }
    })) 
  })
  
  y <- unlist(lapply(starter, function(xx){
    unlist(lapply(1:length(xx), function(j){
      flag <- TRUE
      k <- 1
      if(j > 1){
        while(flag){
          flag <- length(xx[(j-k):j]) == length(unique(xx[(j-k):j]))
          if(!flag){
            break
          }
          else{
            k <- k + 1
          }
          if(k == j){
            break
          }
        }
      }
      k
    }))
  }))
  mean(y)
  
}))))

unique_team <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  c(xx, nrow(unique(pitchers %>% filter(yearID == xx) %>% select(teamID))))
}))

rotation_player <- data.frame(yearID = years, rotation = ceiling(rotation_bound[,2] * unique_team[,2]))

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')

pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
```

```{r}
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'ERA') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- y[1] - (y[2] - y[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qPareto(qbeta(u[j], j + npop[j] -n , n + 1 - j), t = 1, alpha = alpha)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(full_time == 'Y')
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(full_time == 'N') %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}
```

```{r}
pit_thres <- function(component, component_name){
  if (component_name == 'ERA') {
    cutoff <- 0.47
    stab <- 0.2
  }
  if (component_name == 'bWAR_p') {
    cutoff <- 8e-3
    stab <- 0.01
  }
  if (component_name == 'fWAR_p') {
    cutoff <- 5.7e-3
    stab <- 0.01
  }
  if (component_name == 'SO') {
    cutoff <- 1.56
    stab <- 0.2
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}
```

```{r cache=TRUE}
pitchers_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "bWAR_p", year = yy, 
                           ystar = pit_thres(component = pitchers %>% 
                                               filter(full_time =='Y', yearID == yy) %>%
                                               select(comp), component_name = 'bWAR_p'))
})) %>% arrange(-WAR_talent)
```

Rotation adjustment for talent of bWAR.

```{r cache=TRUE}

rotation_talent <- function(target_year){
  WAR_ref <- pitchers_talent_bWAR %>% filter(yearID == target_year, full_time == 'Y')
 team_num <- unique_team[unique_team[,1] == target_year,2]
  rotation_num <- round(rotation_bound$V2[rotation_bound$years == target_year])
   if (rotation_num == 4) {
     WAR_talent <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
       if (xx == target_year) {
         pitchers_talent_bWAR %>% filter(yearID == xx)
       } else
         if (round(rotation_bound$V2[rotation_bound$years == xx]) == 1) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[team_num]
           m
           
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 2) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num*2)]
           m
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 3) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num*3)]
           m
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 4) {
          pitchers_talent_bWAR %>% filter(yearID == xx)
         } else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 5) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           tt <- m$WAR_talent[m$full_time == 'Y'] - WAR_ref$WAR_talent[(nrow(WAR_ref))]
           m$WAR_talent[m$full_time == 'Y'] <- ifelse(tt > 1, tt, 1)
           m
         } 
     }))
     
   }
   if (rotation_num == 5) {
     WAR_talent <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
       if (xx == target_year) {
         pitchers_talent_bWAR %>% filter(yearID == xx)
       } else
         if (round(rotation_bound$V2[rotation_bound$years == xx]) == 1) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num)]
           m
           
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 2) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num*2)]
           m
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 3) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
          m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num*3)]
           m
         }else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 4) {
           m <- pitchers_talent_bWAR %>% filter(yearID == xx) 
           m$WAR_talent[m$full_time == 'Y'] <- m$WAR_talent[m$full_time == 'Y'] + 
             WAR_ref$WAR_talent[(team_num*4)]
           m
         } else if (round(rotation_bound$V2[rotation_bound$years == xx]) == 5) {
           pitchers_talent_bWAR %>% filter(yearID == xx)
         } 
     }))
   }
   WAR_talent %>% mutate(ref_year = target_year) %>% select(playerID, yearID, ref_year, WAR_talent)
 }
 
 t <- rotation_talent(1920)
 for (year in 1921:2021) {
   t <- rbind(t, rotation_talent(year))
 }
write.csv(t, 'rotation_talent_bWAR.csv')
```

For simplicity, we store the results of rotation adjustment for other statistics into the csv files.

```{r cache=TRUE}
mapped_quan_p <- read.csv('mapped_quan_p.csv')[,-1]
rotation_talent <- read.csv('rotation_talent_bWAR.csv')[,-1]

career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  
  do.call(rbind, lapply(snippet$ref_year, function(xx){
    pitchers_int <- dataset %>% filter(yearID == xx, full_time == 'Y')
    
    target_snippet <- snippet %>% filter(ref_year == xx)
    yy <- sort(pitchers_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'ERA') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'bWAR_p'| component_name == 'fWAR_p') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(yy[1] - (yy[2] - yy[1]) < 0, 0, yy[1] - (yy[2] - yy[1]) )
    }
    ytilde[n+1] <- yy[n] + unique(pitchers_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    pitchers_int <- rbind(pitchers_int, target_snippet)
    pitchers_int$pops[nrow(pitchers_int)] <- pitchers_int$pops[1]
    pitchers_int <- pitchers_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    pitchers_int
  }))
} 

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_bWAR$playerID), function(xx){
  m <- pitchers_talent_bWAR %>% filter(playerID == xx) %>% 
    select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
  m
}, mc.cores = ncores)) 

foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
  int <- career_talent(dataset = foo, component_name = 'bWAR_p', 
                       snippet = foo %>% filter(playerID == xx), start_year = yy)
  int
}, mc.cores = ncores)) 
```

```{r cache=TRUE}
career_kAB <- career_kAB %>% 
  mutate(playerID = gsub('.{5}$', '', playerID))

mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                           by = c('playerID', 'yearID', 'ref_year'))

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('IP_thres', 'ref_year')

mapped_pitchers_2 <- merge(mapped_pitchers_1, mapped_cutoff, by = c('ref_year'))

mapped_pitchers_3 <- mapped_pitchers_2 %>% mutate(adj_bWAR = adj_comp * mapped_IP)

min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
  data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
}, mc.cores = ncores)) 

mapped_pitchers <- merge(mapped_pitchers_3, min_refbWAR, 
                         by = c('ref_year'))

career_kAB_trim <- do.call(rbind, mclapply(
  split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    zz <- xx %>% filter(full_time == 'N') %>% 
      mutate(adj_bWAR = (1 - mapped_IP/IP_thres) * bWAR + mapped_IP/IP_thres * (adj_bWAR))
    tt <- xx %>% filter(full_time == 'Y')
    xx <- rbind(zz, tt) %>% arrange(yearID)
    
    m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
      mutate(adj_bWAR = min_bWAR) %>%
      mutate(mapped_IP = adj_bWAR / adj_comp)
    m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
    rbind(m1, m2) %>% arrange(yearID)
  }))

career_kAB_trim_select <- career_kAB_trim 
library(splines)
smoothed_bWAR <- do.call(rbind, mclapply(
  split(career_kAB_trim_select, 
        f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
    nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
    xx %>% mutate(ss_adj_bWAR = ifelse(nn_bWAR < min_bWAR, min_bWAR, nn_bWAR))%>% 
      mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
  })) 

career_pitchers <- do.call(rbind, mclapply(split(smoothed_bWAR, 
                                                 f = droplevels(as.factor(smoothed_bWAR$playerID))), 
                                           mc.cores = ncores, FUN = function(xx){
                                             data.frame(name = unique(xx$name), playerID = unique(xx$playerID), 
                                                        rookie_year = min(xx$yearID), 
                                                        avg_bWAR = sum(xx$avg_bWAR), bWAR = sum(xx$bWAR), span = nrow(xx))
                                           })) %>% arrange(desc(avg_bWAR))

rownames(career_pitchers) <- c()

```

### fWAR

```{r message=FALSE}
pitchers <- read_csv("pitchers_all.csv") %>% select(yearID, bbID, name, teamID, IP, fWAR, pops )
pitchers <- pitchers %>% mutate(comp = fWAR / IP) 
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'
```

```{r}
cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')

pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
```

```{r cache=TRUE}
pitchers_talent_fWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "fWAR_p", year = yy, 
                           ystar = pit_thres(component = pitchers %>% 
                                               filter(full_time =='Y', yearID == yy) %>%
                                               select(comp), component_name = 'fWAR_p'))
})) %>% arrange(-WAR_talent)
```

```{r cache=TRUE}
rotation_talent <- read.csv('rotation_talent_fWAR.csv')[,-1]
yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_fWAR$playerID), function(xx){
  m <- pitchers_talent_fWAR %>% filter(playerID == xx) %>% 
    select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
  m
}, mc.cores = ncores)) 

foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
  int <- career_talent(dataset = foo, component_name = 'fWAR_p', 
                       snippet = foo %>% filter(playerID == xx), start_year = yy)
  int
}, mc.cores = ncores)) 

career_kAB <- career_kAB %>% 
  mutate(playerID = gsub('.{5}$', '', playerID))

mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                           by = c('playerID', 'yearID', 'ref_year'))

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('IP_thres', 'ref_year')

mapped_pitchers_2 <- merge(mapped_pitchers_1, mapped_cutoff, by = c('ref_year'))

mapped_pitchers_3 <- mapped_pitchers_2 %>% mutate(adj_fWAR = adj_comp * mapped_IP)

min_reffWAR <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
  data.frame(ref_year = zz, min_fWAR = min(m$fWAR))
}, mc.cores = ncores)) 

mapped_pitchers <- merge(mapped_pitchers_3, min_reffWAR, 
                         by = c('ref_year'))

career_kAB_trim <- do.call(rbind, mclapply(
  split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    zz <- xx %>% filter(full_time == 'N') %>% 
      mutate(adj_fWAR = (1 - mapped_IP/IP_thres) * fWAR + mapped_IP/IP_thres * (adj_fWAR))
    tt <- xx %>% filter(full_time == 'Y')
    xx <- rbind(zz, tt) %>% arrange(yearID)
    
    m1 <- xx %>% filter(adj_fWAR < min_fWAR) %>% 
      mutate(adj_fWAR = min_fWAR) %>%
      mutate(mapped_IP = adj_fWAR / adj_comp)
    m2 <- xx %>% filter(adj_fWAR >= min_fWAR)
    rbind(m1, m2) %>% arrange(yearID)
  }))

career_kAB_trim_select <- career_kAB_trim %>% 
  select(name, playerID, yearID, adj_fWAR, fWAR, min_fWAR, ref_year)

library(splines)
smoothed_fWAR <- do.call(rbind, mclapply(
  split(career_kAB_trim_select, 
        f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_fWAR = lm(adj_fWAR ~ ns(yearID, df=6), data=xx)
    nn_fWAR <- predict(ns_fWAR, data.frame("yearID"= xx$yearID))
    xx %>% mutate(ss_adj_fWAR = ifelse(nn_fWAR < min_fWAR, min_fWAR, nn_fWAR))%>% 
      mutate(avg_fWAR = (ss_adj_fWAR + adj_fWAR)/2)
  })) 

career_pitchers <- do.call(rbind, mclapply(split(smoothed_fWAR, 
                                                 f = droplevels(as.factor(smoothed_fWAR$playerID))), 
                                           mc.cores = ncores, FUN = function(xx){
                                             data.frame(name = unique(xx$name), playerID = unique(xx$playerID), 
                                                        rookie_year = min(xx$yearID), 
                                                        avg_fWAR = sum(xx$avg_fWAR), fWAR = sum(xx$fWAR), span = nrow(xx))
                                           })) %>% arrange(desc(avg_fWAR))

rownames(career_pitchers) <- c()
```

### ERA

```{r message=FALSE}
pitchers <- read_csv("pitchers_all.csv") %>% 
  select(yearID, bbID, name, teamID, IP, ER_PF, pops) %>% 
  mutate(comp = -9*ER_PF / IP )
pitchers$comp[is.na(pitchers$comp)] = 0
pitchers$comp[is.infinite(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'
```

```{r}
cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')

pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
```

```{r cache=TRUE}
pitchers_talent_ERA <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "ERA", year = yy, 
                           ystar = pit_thres(component = pitchers %>% 
                                               filter(full_time =='Y', yearID == yy) %>%
                                               select(comp), component_name = 'ERA'))
})) %>% arrange(-WAR_talent)
```

```{r cache=TRUE}
rotation_talent <- read.csv('rotation_talent_ERA.csv')[,-1]

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_ERA$playerID), function(xx){
  m <- pitchers_talent_ERA %>% filter(playerID == xx) %>% 
    select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
  m
}, mc.cores = ncores)) 

foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
  int <- career_talent(dataset = foo, component_name = 'ERA', 
                       snippet = foo %>% filter(playerID == xx), start_year = yy)
  int
}, mc.cores = ncores)) 

career_kAB <- career_kAB %>% 
  mutate(playerID = gsub('.{5}$', '', playerID))

mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                           by = c('playerID', 'yearID', 'ref_year')) 

min_refERA <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_pitchers_1 %>% filter(yearID == zz, full_time == 'Y')
  data.frame(ref_year = zz, min_ERA = min(m$comp))
}, mc.cores = ncores)) 

mapped_pitchers_2 <- merge(mapped_pitchers_1, min_refERA, 
                           by = c('ref_year'))

mapped_pitchers <- mapped_pitchers_2 %>% 
  mutate(adj_comp = ifelse(adj_comp < min_ERA, min_ERA, adj_comp))

library(splines)
smoothed_ERA <- do.call(rbind, mclapply(split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), mc.cores = ncores, FUN = function(xx){
  ## natural cubic spline
  ns_ERA = lm(adj_comp ~ ns(yearID, df=6), data=xx)
  nn_ERA <- predict(ns_ERA, data.frame("yearID"= xx$yearID))
  xx %>% mutate(ss_adj_comp = nn_ERA) %>% 
    mutate(avg_ERA = -(ss_adj_comp + adj_comp)/2)
}))

career_pitchers <- do.call(rbind, mclapply(split(smoothed_ERA,f = droplevels(as.factor(smoothed_ERA$playerID))), mc.cores = ncores, FUN = function(xx){
  data.frame(name = unique(xx$name), 
             playerID = unique(xx$playerID), 
             rookie_year = min(xx$yearID), 
             avg_ERA = round(sum(xx$avg_ERA * xx$mapped_IP)/sum(xx$mapped_IP),2), 
             mapped_IP = round(sum(xx$mapped_IP)),
             ERA = round(sum(9*xx$ER_PF)/sum(xx$IP),2), 
             IP = sum(xx$IP), span = nrow(xx))
})) %>% arrange((avg_ERA))

rownames(career_pitchers) <- c()
```

### SO

```{r message=FALSE}
pitchers <- read_csv("pitchers_all.csv") %>% 
  select(yearID, bbID, name, teamID, IP, SO, pops) %>% 
  mutate(comp = SO / IP * 9)
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'
```

```{r}
cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')

pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
```

```{r cache=TRUE}
pitchers_talent_SO <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "SO", year = yy, 
                           ystar = pit_thres(component = pitchers %>% 
                                               filter(full_time =='Y', yearID == yy) %>%
                                               select(comp), component_name = 'SO'))
})) %>% arrange(-WAR_talent)
```

```{r cache=TRUE}
rotation_talent <- read.csv('rotation_talent_SO.csv')[,-1]

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_SO$playerID), function(xx){
  m <- pitchers_talent_SO %>% filter(playerID == xx) %>% 
    select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
  m
}, mc.cores = ncores)) 

foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
  int <- career_talent(dataset = foo, component_name = 'SO', 
                       snippet = foo %>% filter(playerID == xx), start_year = yy)
  int
}, mc.cores = ncores)) 

career_kAB <- career_kAB %>% 
  mutate(playerID = gsub('.{5}$', '', playerID))

mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                           by = c('playerID', 'yearID', 'ref_year'))

mapped_pitchers_2 <- mapped_pitchers_1 %>% 
  mutate(adj_SO = adj_comp * mapped_IP / 9)

min_refSO <- do.call(rbind, mclapply(years, function(zz){
  m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
  data.frame(ref_year = zz, min_SO = min(m$SO))
}, mc.cores = ncores)) 

mapped_pitchers_3 <- merge(mapped_pitchers_2, min_refSO, 
                           by = c('ref_year'))

mapped_pitchers <- mapped_pitchers_3 %>% 
  mutate(adj_SO = ifelse(adj_SO < min_SO, min_SO, adj_SO))

library(splines)
smoothed_SO <- do.call(rbind, mclapply(
  split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
  mc.cores = ncores, FUN = function(xx){
    ## natural cubic spline
    ns_SO = lm(adj_SO ~ ns(yearID, df=6), data=xx)
    nn_SO <- predict(ns_SO, data.frame("yearID"= xx$yearID))
    nn_SO <- ifelse(nn_SO < 0, 0, nn_SO)
    xx %>% mutate(ss_adj_SO = nn_SO) %>%
      mutate(avg_SO = (adj_SO + ss_adj_SO)/2) 
  })) 


career_pitchers <- do.call(rbind, mclapply(split(smoothed_SO, 
                                                 f = droplevels(as.factor(smoothed_SO$playerID))), 
                                           mc.cores = ncores, FUN = function(xx){
                                             data.frame(name = unique(xx$name), 
                                                        playerID = unique(xx$playerID), 
                                                        rookie_year = min(xx$yearID), 
                                                        avg_SO = sum(xx$avg_SO), 
                                                        SO = sum(xx$SO), 
                                                        span = nrow(xx))
                                           })) %>% arrange(desc(avg_SO))

rownames(career_pitchers) <- c()
```

### combined pitching statistics

```{r}
ERA_part <- smoothed_ERA %>% 
  mutate(mapped_IP = round(mapped_IP)) %>% 
  mutate(ER = ER_PF) %>%
  select(yearID, playerID, name, IP, mapped_IP, ER, avg_ERA) 
SO_part <- smoothed_SO %>% 
  mutate(avg_SO = round(avg_SO)) %>% 
  select(yearID, playerID, SO, avg_SO) 
bWAR_part <- smoothed_bWAR %>% 
  mutate(adj_bWAR = round(adj_bWAR, 2)) %>% 
  select(yearID, playerID, age, obs_ER, bWAR, avg_bWAR, FIP, cFIP) 
fWAR_part <- smoothed_fWAR %>% 
  mutate(avg_fWAR = round(avg_fWAR, 2)) %>%
  select(yearID, playerID,fWAR, avg_fWAR) 

master_pitchers <- merge(ERA_part, merge(SO_part, merge(bWAR_part, fWAR_part, by = c('yearID', 'playerID')), 
                                         by = c('yearID', 'playerID')), by = c('yearID', 'playerID'))

```

### final adjustment on pitchers

We extract and remove bad performance season in their career

```{r cache=TRUE}
pitchers <- master_pitchers %>% 
  mutate(adj_K9 = round(avg_SO/mapped_IP*9,1), 
         K9 = round(SO/IP*9,1), 
         avg_fWAR = round(avg_fWAR, 2))
pitchers <- as.data.frame(pitchers)
#pitchers$avg_ERA[pitchers$avg_ERA > 6.20] <- 6.20
pitchers <- pitchers[pitchers$avg_bWAR != 0, ]

## extract and remove bad pitchers 
foo <- pitchers %>% 
  arrange(avg_ERA) %>% 
  filter(mapped_IP >= 100) %>% 
  dplyr::select(name, playerID, yearID, mapped_IP, avg_ERA, avg_SO, avg_fWAR, avg_bWAR)
bar <- split(foo, as.factor(foo$playerID))
baz <- do.call(rbind, lapply(bar, function(m){
  m[which.max(m$avg_fWAR), ]
}))
baz <- baz %>% arrange(avg_fWAR)
bad_players_fWAR <- baz %>% filter(avg_fWAR < 0) %>% pull(playerID)

baz <- do.call(rbind, lapply(bar, function(m){
  m[which.max(m$avg_bWAR), ]
}))
baz <- baz %>% arrange(avg_bWAR)
bad_players_bWAR <- baz %>% filter(avg_bWAR < 0) %>% pull(playerID)
bad_players <- union(bad_players_bWAR, bad_players_fWAR)
pitchers <- pitchers[!pitchers$playerID %in% bad_players, ]

# taper down average WAR for players with small innings
pitchers[pitchers$mapped_IP <= 20, ]$avg_fWAR <- 
  round(pitchers[pitchers$mapped_IP <= 20, ]$avg_fWAR/9,2)
pitchers[pitchers$mapped_IP <= 20, ]$avg_bWAR <- 
  round(pitchers[pitchers$mapped_IP <= 20, ]$avg_bWAR/9,2)	
pitchers[pitchers$mapped_IP <= 40 & pitchers$mapped_IP > 20 & pitchers$avg_ERA > 4, ]$avg_fWAR <- 
  round(pitchers[pitchers$mapped_IP <= 40 & pitchers$mapped_IP > 20 & pitchers$avg_ERA > 4, ]$avg_fWAR/9, 2)
pitchers[pitchers$mapped_IP <= 40 & pitchers$mapped_IP > 20 & pitchers$avg_ERA > 4, ]$avg_bWAR <- 
  round(pitchers[pitchers$mapped_IP <= 40 & pitchers$mapped_IP > 20 & pitchers$avg_ERA > 4, ]$avg_bWAR/9, 2)

## build adjusted data set
pitchers_adjusted <- pitchers %>% dplyr::select(name, playerID, age, yearID, 
                                                mapped_IP, avg_ERA, avg_SO, avg_bWAR, avg_fWAR)
colnames(pitchers_adjusted) <- c("name", "playerID", "age", "year", "IP", 
                                 "ERA", "SO", "ebWAR", "efWAR")
pitchers_adjusted$playerID <- droplevels(as.factor(pitchers_adjusted$playerID))
pitchers_adjusted <- pitchers_adjusted[!is.na(pitchers_adjusted$age), ]


## trim out bad players
# first round
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
})
checker <- data.frame(pid = levels(pitchers_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
pitchers_adjusted <- pitchers_adjusted %>% 
  filter(!pitchers_adjusted$playerID %in% rownames(checker)[checker$m_bad == 2])
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

# second round
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
})
checker <- data.frame(pid = levels(pitchers_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
pitchers_adjusted <- pitchers_adjusted %>% 
  filter(!pitchers_adjusted$playerID %in% rownames(checker)[checker$m_bad >= 1 & checker$len <= 2])
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

# third round
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  min(ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0))
})
checker <- data.frame(pid = levels(pitchers_adjusted$playerID), 
                      m_bad = unlist(lapply(bar, mean)), 
                      len = unlist(lapply(bar, length)))
pitchers_adjusted <- pitchers_adjusted %>% 
  filter(!pitchers_adjusted$playerID %in% rownames(checker)[checker$m_bad >= 1])
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

## remove tails
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- sum(c(ifelse(sum(tail(bad, 2)) >= 3,1,0), 
                    ifelse(sum(tail(bad, 3)) >= 5,1,0), 
                    ifelse(sum(tail(bad, 4)) >= 7,1,0),
                    ifelse(sum(tail(bad, 5)) >= 9,1,0), 
                    ifelse(sum(tail(bad, 6)) >= 11,1,0)))
  c(length(bad), 1:(length(bad)-bad_tail))
  1:(length(bad)-bad_tail)
})
pitchers_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- c(ifelse(sum(tail(bad, 3)) >= 4,1,0), 
                ifelse(sum(tail(bad, 4)) >= 5,1,0), 
                ifelse(sum(tail(bad, 5)) >= 7,1,0), 
                ifelse(sum(tail(bad, 6)) >= 8,1,0), 
                ifelse(sum(tail(bad, 7)) >= 9,1,0),
                ifelse(sum(tail(bad, 8)) >= 10,1,0),
                ifelse(sum(tail(bad, 9)) >= 11,1,0))
  int <- 1:length(bad)
  if(any(bad_tail == 1)) int <- 1:(length(bad) - max(which(bad_tail == 1)))
  int
})
pitchers_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

## remove starts
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_head <- sum(c(ifelse(sum(head(bad, 2)) >= 3,1,0), 
                    ifelse(sum(head(bad, 3)) >= 5,1,0), 
                    ifelse(sum(head(bad, 4)) >= 7,1,0),
                    ifelse(sum(head(bad, 5)) >= 9,1,0), 
                    ifelse(sum(head(bad, 6)) >= 11,1,0)))
  (bad_head + 1):length(bad)
})
pitchers_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)

## remove tails (take 2)
foo <- split(pitchers_adjusted, f = pitchers_adjusted$playerID)
bar <- lapply(foo, function(m){
  bad <- ifelse(m$ebWAR <= 0, 1, 0) + ifelse(m$efWAR <= 0, 1, 0)
  bad_tail <- sum(c(ifelse(sum(tail(bad, 2)) >= 3,1,0), 
                    ifelse(sum(tail(bad, 3)) >= 5,1,0), 
                    ifelse(sum(tail(bad, 4)) >= 7,1,0),
                    ifelse(sum(tail(bad, 5)) >= 9,1,0), 
                    ifelse(sum(tail(bad, 6)) >= 11,1,0)))
  c(length(bad), 1:(length(bad)-bad_tail))
  1:(length(bad)-bad_tail)
})
pitchers_adjusted <- do.call(rbind, lapply(1:length(bar), function(j){
  foo[[j]][bar[[j]], ]
})) %>% arrange(year)
pitchers_adjusted$playerID <- droplevels(pitchers_adjusted$playerID)
pitchers_adjusted <- pitchers_adjusted %>% 
  mutate(ER = round(ERA * IP / 9)) %>%
  mutate(ERA = round(ER / IP *9, 2)) %>% 
  mutate(ERA = ifelse(is.na(ERA), 0, ERA))

career_pitchers <- pitchers_adjusted %>% group_by(playerID) %>% 
  summarise(name = unique(name), 
             key_bbref = unique(playerID), 
             IP = round(sum(IP)), 
             ER = round(sum(ER)), 
             ERA = round(9*sum(ER) / round(sum(IP)), 2), 
             K = sum(SO),  
             ebWAR = round(sum(ebWAR),2), 
             efWAR = round(sum(efWAR),2)) %>%
  arrange(desc(ebWAR)) %>% ungroup()
career_pitchers <- career_pitchers %>% 
  mutate(ERA = ifelse(is.na(ERA), 0, ERA)) %>% 
  mutate(IP = ifelse(IP ==0, 1, IP))

## IP ranking list
(career_pitchers %>% 
  arrange(desc(IP)))[1:25,]

## ERA ranking list
(career_pitchers %>% 
  arrange(ERA) %>% filter(IP >= 1500))[1:25,]

## SO ranking list
(career_pitchers %>% 
  arrange(desc(K)))[1:25,]

## bWAR ranking list
(career_pitchers %>% 
  arrange(desc(ebWAR)))[1:25,]

## fWAR ranking list
(career_pitchers %>% 
  arrange(desc(efWAR)))[1:25,]

```

### Combined ranking lists for bWAR and fWAR

```{r}
## bWAR
m_b <- career_batters %>% 
  select(name, key_bbref, ebWAR)

m_p <- career_pitchers %>% 
  select(name, key_bbref, ebWAR)

m_ebWAR<- rbind(m_b, m_p)

index <- which(m_ebWAR$name == "Babe Ruth")
m_ebWAR$ebWAR[index[1]] <- sum(m_ebWAR$ebWAR[index])
index <- which(m_ebWAR$name == "Shohei Ohtani")
m_ebWAR$ebWAR[index[1]] <- sum(m_ebWAR$ebWAR[index])

(m_ebWAR%>% arrange(desc(ebWAR)))[1:25,]

## bWAR
m_b <- career_batters %>% 
  select(name, key_bbref, efWAR)

m_p <- career_pitchers %>% 
  select(name, key_bbref, efWAR)

m_efWAR<- rbind(m_b, m_p)

index <- which(m_efWAR$name == "Babe Ruth")
m_efWAR$efWAR[index[1]] <- sum(m_efWAR$efWAR[index])
index <- which(m_efWAR$name == "Shohei Ohtani")
m_efWAR$efWAR[index[1]] <- sum(m_efWAR$efWAR[index])

(m_efWAR %>% arrange(desc(efWAR)))[1:25,]

bWAR <- c('Babe Ruth', 'Walter Johnson', 'Cy Young', 
          'Barry Bonds', 'Willie Mays', 'Ty Cobb', 
          'Hank Aaron', 'Roger Clements', 'Tris Speaker', 
          'Honus Wagner', 'Stan Musial', 'Rogers Hornsby', 
          'Eddie Collins', 'Ted Williams', 'Pete Alexander',
          'Alex Rodrigues', 'Kid Nichols', 'Lou Gehrig', 
          'Rickey Herderson', 'Mel Ott', 'Mickey Mantle', 
          'Tom Seaver', 'Frank Robinson', 'Nap Lajole', 
          'Mike Schmidt')

fWAR <- c('Babe Ruth', 'Barry Bonds', 'Willie Mays', 
          'Ty Cobb', 'Honus Wagner', 'Hank Aaron', 
          'Roger Clemens', 'Cy Young', 'Tris Speaker', 
          'Ted Williams', 'Rogers Hornsby', 'Stan Musial',
          'Eddie Collins', 'Walter Johnson', 'Greg Maddux',
          'Lou Gehrig', 'Alex Rodriguez', 'Mickey Mantle', 
          'Mel Ott', 'Randy Johnson', 'Nolan Ryan', 
          'Mike Schmidt', 'Rickey Henderson', 
          'Frank Robinson', 'Bert Blyleven')

ESPN <- c('Babe Ruth', 'Willie Mays', 'Hank Aaron', 
          'Ty Cobb', 'Ted Williams', 'Lou Gehrig', 
          'Mickey Mantle', 'Barry Bonds', 'Walter Johnson',
          'Stan Musial', 'Pedro Martinez', 'Honus Wagner',
          'Ken Griffey Jr.', 'Greg Maddux', 'Mike Trout',
          'Joe DiMaggio', 'Roger Clemens', 'Mike Schmidt',
          'Frank Robinson', 'Rogeres Hornsby', 'Cy Young',
          'Tom Seaver', 'Rickey Henderson', 'Randy Johnson',
          'Christy Mathewson')

HOS <- c('Babe Ruth', 'Barry Bonds', 'Walter Johnson', 
         'Willie Mays', 'Cy Young', 'Ty Cobb', 
         'Hank Aaron', 'Roger Clemens', 'Rogers Hornsby',
         'Houns Wagner', 'Tris Speaker', 'Ted Williams',
         'Stan Musial', 'Eddie Collins', 'Pete Alexander',
         'Alex Rodriguez', 'Lou Gehrig', 'Mickey Mantle',
         'Lefty Grove', 'Mel Ott', 'Rickey Henderson', 
         'Kid Nichols', 'Mike Schmidt', 'Nap Lajoie',
         'Christy Mathewson')

WAR_rankings <- cbind((m_ebWAR%>% arrange(desc(ebWAR)))$name[1:25], (m_efWAR%>% arrange(desc(efWAR)))$name[1:25], bWAR, fWAR, ESPN, HOS)

colnames(WAR_rankings) <- c('ebWAR', 'efWAR', 'bWAR', 'fWAR', 'ESPN', 'Hall of Stats')

## pre-1950 in top 10
WAR_rankings <- rbind(WAR_rankings, c(1,1,6,6,6,6))

## pre-1950 in top 25
WAR_rankings <- rbind(WAR_rankings, c(4,4,15,12,11,17))

## proportion before 1950

WAR_rankings <- rbind(WAR_rankings, rep(0.190,6))

## chances of observing old era players in top 10

WAR_rankings <- rbind(WAR_rankings, c(1 / (1 - pbinom(as.numeric(WAR_rankings[26,1])-1, 10, as.numeric(WAR_rankings[28,1]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[26,2])-1, 10, as.numeric(WAR_rankings[28,2]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[26,3])-1, 10, as.numeric(WAR_rankings[28,3]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[26,4])-1, 10, as.numeric(WAR_rankings[28,4]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[26,5])-1, 10, as.numeric(WAR_rankings[28,5]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[26,6])-1, 10, as.numeric(WAR_rankings[28,6])))))

## chances of observing old era players in top 25

WAR_rankings <- rbind(WAR_rankings, c(1 / (1 - pbinom(as.numeric(WAR_rankings[27,1])-1, 25, as.numeric(WAR_rankings[28,1]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[27,2])-1, 25, as.numeric(WAR_rankings[28,2]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[27,3])-1, 25, as.numeric(WAR_rankings[28,3]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[27,4])-1, 25, as.numeric(WAR_rankings[28,4]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[27,5])-1, 25, as.numeric(WAR_rankings[28,5]))), 1 / (1 - pbinom(as.numeric(WAR_rankings[27,6])-1, 25, as.numeric(WAR_rankings[28,6])))))
```

# Distribution Sensitity Analysis

```{r cache=TRUE}
library(tidyverse)
library(orderstats)
library(Pareto)
library(parallel)
library(doParallel)
library(xtable)
library(VGAM)
RNGkind("L'Ecuyer-CMRG")


## order_pnorm function
# converts normal order stats to their percentiles
order_pnorm <- function(q = 0, mean = 0, sd = 1, k = 1, n = 1e4){
	p <- pnorm(q, mean = mean, sd = sd)
	pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
}

## order_pnorm_vec function
# this function converts a vector of normal order stats 
# to their percentiles. This vector should be the entire 
# sample sorted in increasing order
order_pnorm_vec <- function(q, mean = 0, sd = 1){
	q <- sort(q) # just in case
	n <- length(q)
	unlist(lapply(1:n, function(j){
		order_pnorm(q[j], k = j, n = n, mean = mean, sd = sd)
	}))
}

## order_Pareto_vec function 
# this function transform percentiles from order stats (in increasing order)
# to Pareto values corresponding to the general population 
# of a greater than or equal to size
# default alpha is that of the Pareto principle 80-20
order_Pareto_vec <- function(u, t = 1, alpha = 1.16, npop = 1e4){
	n <- length(u)
	if(length(npop) == 1) npop <- rep(npop, n)
	unlist(lapply(1:n, function(j){
		qPareto(qbeta(u[j], j + npop[j]-n, n + 1 - j), t = t, alpha = alpha)
	}))
}
## order_normal_vec function 
# this function transform percentiles from order stats (in increasing order)
# to normal values corresponding to the general population 
# of a greater than or equal to size
# default alpha is that of the Pareto principle 80-20
order_normal_vec <- function(u, mean = 0, sd = 1, npop = 1e4){
  n <- length(u)
  if(length(npop) == 1) npop <- rep(npop, n)
  unlist(lapply(1:n, function(j){
    qnorm(qbeta(u[j], j + npop[j]-n, n + 1 - j), mean = mean, sd = sd)
  }))
}

## map_Pareto_vals_vec function 
# this function transforms ordered Pareto values corresponding to 
# the general population to percentiles from order stats 
# (in increasing order)
map_Pareto_vals_vec <- function(x, t = 1, alpha = 1.16, npop = 1e4){
	n <- length(x)
	if(length(npop) == 1) npop <- rep(npop, n)  
	unlist(lapply(1:n, function(j){
		pbeta(pPareto(x[j], t = t, alpha = alpha), j + npop[j]-n, n + 1 - j)
	}))
}

## map_Normal_vals_vec function 
# this function transforms ordered Normal values corresponding to 
# the general population to percentiles from order stats 
# (in increasing order)
map_Normal_vals_vec <- function(x, mean = 0, sd = 1, npop = 1e4){
	n <- length(x)
	if(length(npop) == 1) npop <- rep(npop, n)  
	unlist(lapply(1:n, function(j){
		pbeta(pnorm(x[j], mean = mean, sd = sd), j + npop[j]-n, n + 1 - j)
	}))
}

## order_foldedN_vec function 
# this function transform percentiles from order stats (in increasing order)
# to folded normal values corresponding to the general population 
# of a greater than or equal to size
# default alpha is that of the Pareto principle 80-20
order_foldedN_vec <- function(u, mean = 0, sd = 1, npop = 1e4){
  n <- length(u)
  if(length(npop) == 1) npop <- rep(npop, n)
  unlist(lapply(1:n, function(j){
    qfoldnorm(qbeta(u[j], j + npop[j]-n, n + 1 - j), mean = 0, sd = 1)
  }))
}

## map_foldedN_vals_vec function 
# this function transforms ordered folded normal values corresponding to 
# the general population to percentiles from order stats 
# (in increasing order)
map_foldedN_vals_vec <- function(x, mean = 0, sd = 1, npop = 1e4){
  n <- length(x)
  if(length(npop) == 1) npop <- rep(npop, n)  
  unlist(lapply(1:n, function(j){
    pbeta(pfoldnorm(x[j], mean = mean, sd = sd), j + npop[j]-n, n + 1 - j)
  }))
}


## oder_qnorm function
# take the ordered percentiles and convert them to order statistics 
# from a normal distribution
order_qnorm <- function(u, mean = 0, sd = 1){
	n <- length(u)
	qnorm(qbeta(u, shape1 = 1:n, shape2 = n:1), mean = mean, sd = sd)
}


Full_House_averages_simulator <- function(l_size = 300, alpha = 1.16, alpha2 = 3, ncores = 1){

	### Correct Pareto talent model (alpha)	
	league1 <- sort(rPareto(n = 1e6, t = 1, alpha = alpha))
	league2 <- sort(rPareto(n = 2e6, t = 1, alpha = alpha))
	league3 <- sort(rPareto(n = 4e6, t = 1, alpha = alpha))
	league4 <- sort(rPareto(n = 8e6, t = 1, alpha = alpha))
	league5 <- sort(rPareto(n = 16e6, t = 1, alpha = alpha))

	dat_talent = data.frame(
		id = 1:(5*l_size), 
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		talent = c(tail(league1, l_size), tail(league2, l_size), tail(league3, l_size), 
							 tail(league4, l_size), tail(league5, l_size)))
	
	averages1 <- order_qnorm(map_Pareto_vals_vec(tail(league1, l_size), alpha = alpha, npop = 1e6), mean = 0.280, sd = 0.040)
	averages2 <- order_qnorm(map_Pareto_vals_vec(tail(league2, l_size), alpha = alpha, npop = 2e6), mean = 0.275, sd = 0.0375)
	averages3 <- order_qnorm(map_Pareto_vals_vec(tail(league3, l_size), alpha = alpha, npop = 4e6), mean = 0.270, sd = 0.035)
	averages4 <- order_qnorm(map_Pareto_vals_vec(tail(league4, l_size), alpha = alpha, npop = 8e6), mean = 0.265, sd = 0.0325)
	averages5 <- order_qnorm(map_Pareto_vals_vec(tail(league5, l_size), alpha = alpha, npop = 16e6), mean = 0.260, sd = 0.03)
	
	dat_averages = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		averages = c(as.vector(averages1), as.vector(averages2), as.vector(averages3), 
								 as.vector(averages4), as.vector(averages5)))
	dat_Zscores = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		Zscores = c(as.vector(scale(averages1)), as.vector(scale(averages2)), as.vector(scale(averages3)),
								as.vector(scale(averages4)), as.vector(scale(averages5))))
	
	# correct population
	batters_talent_AVG <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)
	
	# missed population (1/2, 3/4, 5/6, 7/8, 9/10)
	batters_talent_AVG_Nmiss1 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1 - 1/(2*yy))
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)

	# missed population (1, 1/2, 1/3, 1/4, 1/5)
	batters_talent_AVG_Nmiss2 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1/yy)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)
	
	# how many in top 25 correctly identified
	Pareto_correct <- c(
		## Full House Method (N correct)
		length(which((batters_talent_AVG %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])), 
		## Full House Method (N incorrect 1)
		length(which((batters_talent_AVG_Nmiss1 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Full House Method (N incorrect 2)
		length(which((batters_talent_AVG_Nmiss2 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Z scores
		length(which((dat_Zscores %>% arrange(-Zscores))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## raw averages
		length(which((dat_averages %>% arrange(-averages))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])))
	
	
	### Misspecified Pareto talent model (alpha2)
	league1 <- sort(rPareto(n = 1e6, t = 1, alpha = alpha2))
	league2 <- sort(rPareto(n = 2e6, t = 1, alpha = alpha2))
	league3 <- sort(rPareto(n = 4e6, t = 1, alpha = alpha2))
	league4 <- sort(rPareto(n = 8e6, t = 1, alpha = alpha2))
	league5 <- sort(rPareto(n = 16e6, t = 1, alpha = alpha2))
	
	dat_talent = data.frame(
		id = 1:(5*l_size), 
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		talent = c(tail(league1, l_size), tail(league2, l_size), tail(league3, l_size), 
							 tail(league4, l_size), tail(league5, l_size)))

	averages1 <- order_qnorm(map_Pareto_vals_vec(tail(league1, l_size), alpha = alpha2, npop = 1e6), mean = 0.280, sd = 0.040)
	averages2 <- order_qnorm(map_Pareto_vals_vec(tail(league2, l_size), alpha = alpha2, npop = 2e6), mean = 0.275, sd = 0.0375)
	averages3 <- order_qnorm(map_Pareto_vals_vec(tail(league3, l_size), alpha = alpha2, npop = 4e6), mean = 0.270, sd = 0.035)
	averages4 <- order_qnorm(map_Pareto_vals_vec(tail(league4, l_size), alpha = alpha2, npop = 8e6), mean = 0.265, sd = 0.0325)
	averages5 <- order_qnorm(map_Pareto_vals_vec(tail(league5, l_size), alpha = alpha2, npop = 16e6), mean = 0.260, sd = 0.03)
	
	dat_averages = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		averages = c(as.vector(averages1), as.vector(averages2), as.vector(averages3), 
								 as.vector(averages4), as.vector(averages5)))

	dat_Zscores = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		Zscores = c(as.vector(scale(averages1)), as.vector(scale(averages2)), as.vector(scale(averages3)),
								as.vector(scale(averages4)), as.vector(scale(averages5))))

	# correct population
	batters_talent_AVG <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)

	# missed population (1/2, 3/4, 5/6, 7/8, 9/10)
	batters_talent_AVG_Nmiss1 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1 - 1/(2*yy))
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)

	# missed population (1, 1/2, 1/3, 1/4, 1/5)
	batters_talent_AVG_Nmiss2 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1/yy)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_Pareto_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)

	# how many in top 25 correctly identified
	Pareto_incorrect <- c(
		## Full House Method (N correct)
		length(which((batters_talent_AVG %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])), 
		## Full House Method (N incorrect 1)
		length(which((batters_talent_AVG_Nmiss1 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Full House Method (N incorrect 2)
		length(which((batters_talent_AVG_Nmiss2 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Z scores
		length(which((dat_Zscores %>% arrange(-Zscores))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## raw averages
		length(which((dat_averages %>% arrange(-averages))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])))
	
	
	### Misspecified Normal talent model
	league1 <- sort(rnorm(n = 1e6, mean = 0, sd = 1))
	league2 <- sort(rnorm(n = 2e6, mean = 0, sd = 1))
	league3 <- sort(rnorm(n = 4e6, mean = 0, sd = 1))
	league4 <- sort(rnorm(n = 8e6, mean = 0, sd = 1))
	league5 <- sort(rnorm(n = 16e6, mean = 0, sd = 1))
	
	dat_talent = data.frame(
		id = 1:(5*l_size), 
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		talent = c(tail(league1, l_size), tail(league2, l_size), tail(league3, l_size), 
							 tail(league4, l_size), tail(league5, l_size)))
	
	averages1 <- order_qnorm(map_Normal_vals_vec(tail(league1, l_size), npop = 1e6), mean = 0.280, sd = 0.040)
	averages2 <- order_qnorm(map_Normal_vals_vec(tail(league2, l_size), npop = 2e6), mean = 0.275, sd = 0.0375)
	averages3 <- order_qnorm(map_Normal_vals_vec(tail(league3, l_size), npop = 4e6), mean = 0.270, sd = 0.035)
	averages4 <- order_qnorm(map_Normal_vals_vec(tail(league4, l_size), npop = 8e6), mean = 0.265, sd = 0.0325)
	averages5 <- order_qnorm(map_Normal_vals_vec(tail(league5, l_size), npop = 16e6), mean = 0.260, sd = 0.03)
	
	dat_averages = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		averages = c(as.vector(averages1), as.vector(averages2), as.vector(averages3), 
								 as.vector(averages4), as.vector(averages5)))
	
	dat_Zscores = data.frame(
		id = 1:(5*l_size),   
		league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
		Zscores = c(as.vector(scale(averages1)), as.vector(scale(averages2)), as.vector(scale(averages3)),
								as.vector(scale(averages4)), as.vector(scale(averages5))))
	
	# correct population
	batters_talent_AVG <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_normal_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)
	
	# missed population (1/2, 3/4, 5/6, 7/8, 9/10)
	batters_talent_AVG_Nmiss1 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1 - 1/(2*yy))
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_normal_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)
	
	# missed population (1, 1/2, 1/3, 1/4, 1/5)
	batters_talent_AVG_Nmiss2 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
		foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
		nsys <- nrow(foo)
		mu_AVG <- mean(foo$averages)
		sd_AVG <- sd(foo$averages)
		AVG_sorted <- foo$averages
		pops <- 1e6 * 2^(yy - 1) * (1/yy)
		u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
		foo <- foo %>% mutate(AVG_talent = order_normal_vec(u_int, npop = pops))
		foo
	})) %>% arrange(-AVG_talent)
	
	## Full House Method (N correct)
	length(which((batters_talent_AVG %>% arrange(-AVG_talent))[1:25, 1] %in% 
							 	(dat_talent %>% arrange(-talent))[1:25, 1]))
	
	## Full House Method (N incorrect 1)
	length(which((batters_talent_AVG_Nmiss1 %>% arrange(-AVG_talent))[1:25, 1] %in% 
							 	(dat_talent %>% arrange(-talent))[1:25, 1]))
	
	## Full House Method (N incorrect 2)
	length(which((batters_talent_AVG_Nmiss2 %>% arrange(-AVG_talent))[1:25, 1] %in% 
							 	(dat_talent %>% arrange(-talent))[1:25, 1]))
	
	## Z scores
	length(which((dat_Zscores %>% arrange(-Zscores))[1:25, 1] %in% 
							 	(dat_talent %>% arrange(-talent))[1:25, 1]))
	
	## raw averages
	length(which((dat_averages %>% arrange(-averages))[1:25, 1] %in% 
							 	(dat_talent %>% arrange(-talent))[1:25, 1]))
	
	
	# how many in top 25 correctly identified
	Normal_incorrect <- c(
		## Full House Method (N correct)
		length(which((batters_talent_AVG %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])), 
		## Full House Method (N incorrect 1)
		length(which((batters_talent_AVG_Nmiss1 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Full House Method (N incorrect 2)
		length(which((batters_talent_AVG_Nmiss2 %>% arrange(-AVG_talent))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## Z scores
		length(which((dat_Zscores %>% arrange(-Zscores))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])),
		## raw averages
		length(which((dat_averages %>% arrange(-averages))[1:25, 1] %in% 
								 	(dat_talent %>% arrange(-talent))[1:25, 1])))
	
	### incorrect folded normal talent model	
	league1 <- sort(rfoldnorm(n = 1e6))
	league2 <- sort(rfoldnorm(n = 2e6))
	league3 <- sort(rfoldnorm(n = 4e6))
	league4 <- sort(rfoldnorm(n = 8e6))
	league5 <- sort(rfoldnorm(n = 16e6))
	
	dat_talent = data.frame(
	  id = 1:(5*l_size), 
	  league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
	  talent = c(tail(league1, l_size), tail(league2, l_size), tail(league3, l_size), 
	             tail(league4, l_size), tail(league5, l_size)))
	
	averages1 <- order_qnorm(map_foldedN_vals_vec(tail(league1, l_size), npop = 1e6), mean = 0.280, sd = 0.040)
	averages2 <- order_qnorm(map_foldedN_vals_vec(tail(league2, l_size), npop = 2e6), mean = 0.275, sd = 0.0375)
	averages3 <- order_qnorm(map_foldedN_vals_vec(tail(league3, l_size), npop = 4e6), mean = 0.270, sd = 0.035)
	averages4 <- order_qnorm(map_foldedN_vals_vec(tail(league4, l_size), npop = 8e6), mean = 0.265, sd = 0.0325)
	averages5 <- order_qnorm(map_foldedN_vals_vec(tail(league5, l_size), npop = 16e6), mean = 0.260, sd = 0.03)
	
	dat_averages = data.frame(
	  id = 1:(5*l_size),   
	  league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
	  averages = c(as.vector(averages1), as.vector(averages2), as.vector(averages3), 
	               as.vector(averages4), as.vector(averages5)))
	dat_Zscores = data.frame(
	  id = 1:(5*l_size),   
	  league = c(rep(1, l_size), rep(2, l_size), rep(3, l_size), rep(4, l_size), rep(5, l_size)), 
	  Zscores = c(as.vector(scale(averages1)), as.vector(scale(averages2)), as.vector(scale(averages3)),
	              as.vector(scale(averages4)), as.vector(scale(averages5))))
	
	# correct population
	batters_talent_AVG <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
	  foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
	  nsys <- nrow(foo)
	  mu_AVG <- mean(foo$averages)
	  sd_AVG <- sd(foo$averages)
	  AVG_sorted <- foo$averages
	  pops <- 1e6 * 2^(yy - 1)
	  u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
	  foo <- foo %>% mutate(AVG_talent = order_foldedN_vec(u_int, npop = pops))
	  foo
	})) %>% arrange(-AVG_talent)
	
	# missed population (1/2, 3/4, 5/6, 7/8, 9/10)
	batters_talent_AVG_Nmiss1 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
	  foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
	  nsys <- nrow(foo)
	  mu_AVG <- mean(foo$averages)
	  sd_AVG <- sd(foo$averages)
	  AVG_sorted <- foo$averages
	  pops <- 1e6 * 2^(yy - 1) * (1 - 1/(2*yy))
	  u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
	  foo <- foo %>% mutate(AVG_talent = order_foldedN_vec(u_int, npop = pops))
	  foo
	})) %>% arrange(-AVG_talent)
	
	# missed population (1, 1/2, 1/3, 1/4, 1/5)
	batters_talent_AVG_Nmiss2 <- do.call(rbind, mclapply(1:5, mc.cores = ncores, function(yy){
	  foo <- dat_averages %>% filter(league == yy) %>% arrange(averages)
	  nsys <- nrow(foo)
	  mu_AVG <- mean(foo$averages)
	  sd_AVG <- sd(foo$averages)
	  AVG_sorted <- foo$averages
	  pops <- 1e6 * 2^(yy - 1) * (1/yy)
	  u_int <- order_pnorm_vec(AVG_sorted, mean = mu_AVG, sd = sd_AVG)
	  foo <- foo %>% mutate(AVG_talent = order_foldedN_vec(u_int, npop = pops))
	  foo
	})) %>% arrange(-AVG_talent)
	
	# how many in top 25 correctly identified
	foldedN_incorrect <- c(
	  ## Full House Method (N correct)
	  length(which((batters_talent_AVG %>% arrange(-AVG_talent))[1:25, 1] %in% 
	                 (dat_talent %>% arrange(-talent))[1:25, 1])), 
	  ## Full House Method (N correct)
	  length(which((batters_talent_AVG_Nmiss1 %>% arrange(-AVG_talent))[1:25, 1] %in% 
	                 (dat_talent %>% arrange(-talent))[1:25, 1])),
	  ## Full House Method (N incorrect 4)
	  length(which((batters_talent_AVG_Nmiss2 %>% arrange(-AVG_talent))[1:25, 1] %in% 
	                 (dat_talent %>% arrange(-talent))[1:25, 1])),
	  ## Z scores (N incorrect 13)
	  length(which((dat_Zscores %>% arrange(-Zscores))[1:25, 1] %in% 
	                 (dat_talent %>% arrange(-talent))[1:25, 1])),
	  ## raw averages (N incorrect 20)
	  length(which((dat_averages %>% arrange(-averages))[1:25, 1] %in% 
	                 (dat_talent %>% arrange(-talent))[1:25, 1])))
	
	
	
	
	
	
	 # output
	 c(Pareto_correct, Pareto_incorrect, Normal_incorrect, foldedN_incorrect)
		
}

set.seed(13)
out <- do.call(rbind, mclapply(1:200, function(xx) Full_House_averages_simulator(), mc.cores = 7))
out <- as.data.frame(out)

m_out <- do.call(rbind, mclapply(1:20, function(xx) cbind(out[,xx], case = xx %% 5), mc.cores = 7))
m_out <- as.data.frame(m_out, stringsAsFactors=FALSE)
dist <- c(rep('A',1000), rep('B',1000), rep('C',1000), rep('D',1000))
m_out <- cbind(m_out, index = dist, rank = m_out$case)
m_out$rank[m_out$rank == 0] <- 5

m_out$case[m_out$case == 1] <- 'Correct Population'
m_out$case[m_out$case == 2] <- 'Population Estimation Improved'
m_out$case[m_out$case == 3] <- 'Population Estimation Deteriorated'
m_out$case[m_out$case == 4] <- 'Z-Scores'
m_out$case[m_out$case == 0] <- 'Raw BA'

library(ggpubr)
m_out$index[m_out$index == 'A'] = 'Pareto Distribution'
m_out$index[m_out$index == 'B'] = 'Misspecified Pareto Distribution'
m_out$index[m_out$index == 'C'] = 'Normal Distribution'
m_out$index[m_out$index == 'D'] = 'Folded Normal Distribution'
```

## Figure 3: Distribution sensitivity analysis in the paper

```{r}
ggplot() + geom_boxplot(data = m_out[1:1000,], mapping = aes(y=V1, x = reorder(case, -rank), color = case), lwd = 1) +
  geom_point(data = m_out[1:1000,], mapping = aes(y=V1, x = case, color = case))  + 
  geom_jitter(data = m_out[1:1000,], mapping = aes(y=V1, x = case, color = case), shape=16, position=position_jitter(0.2))  + 
  geom_boxplot(data = m_out[1001:2000,], mapping = aes(y=V1, x = case, color = case), lwd = 1) +
  geom_point(data = m_out[1001:2000,], mapping = aes(y=V1, x = case, color = case))  + 
  geom_jitter(data = m_out[1001:2000,], mapping = aes(y=V1, x = case, color = case), shape=16, position=position_jitter(0.2)) + 
  geom_boxplot(data = m_out[2001:3000,], mapping = aes(y=V1, x = case, color = case), lwd = 1) +
  geom_point(data = m_out[2001:3000,], mapping = aes(y=V1, x = case, color = case))  + 
  geom_jitter(data = m_out[2001:3000,], mapping = aes(y=V1, x = case, color = case), shape=16, position=position_jitter(0.2)) + 
  geom_boxplot(data = m_out[3001:4000,], mapping = aes(y=V1, x = case, color = case), lwd = 1) +
  geom_point(data = m_out[3001:4000,], mapping = aes(y=V1, x = case, color = case))  + 
  geom_jitter(data = m_out[3001:4000,], mapping = aes(y=V1, x = case, color = case), shape=16, position=position_jitter(0.2))  + 
  facet_grid(cols = vars(index))+ coord_flip()  +  xlab("") + ylab('Number of Players that are Correctly Identified in Top-25 Talents')
```

## Table 5: Comparsion between deteriorated estimation regime and Z-scores in the paper.

```{r}

# The probability that incorrect Full House Model beats or ties Schell’s method and strictly beats Schell’s method

m <- rowMeans(apply(out, 1, function(xx){
	c(as.numeric(xx[3] >= xx[4]), as.numeric(xx[8] >= xx[9]), as.numeric(xx[13] >= xx[14]), as.numeric(xx[18] >= xx[19]), 
		as.numeric(xx[3] > xx[4]), as.numeric(xx[8] > xx[9]), as.numeric(xx[13] > xx[14]), as.numeric(xx[18] > xx[19]))
}))

n <- as.data.frame(t(matrix(m, nrow = 4)))
colnames(n) <- c('correct Pareto dist', 'incorrect Pareto dist', 'normal dist', 'folded normal dist')
rownames(n) <- c('beat or ties', 'strictly beat')
n

```

# Ranking Stability Analysis

By changing the starting year from 1946 to 1995, we obtain 50 bWAR ranking lists for batters and pitchers. These ranking lists are stored in the combined_bp_46_95.RData.

```{r cache=TRUE}
load('combined_bp_46_95.RData')

ranks <- combined_bp[, ((1:50)*2-1)]

## find the starting year that all the top 25 players lie in the
## 10-90 percentile intervals.
for (k in 1:50) {
  n <- rep(0,25)
  for (j in 1:25) {
    m <- rep(0,50)
    for (i in 1:50) {
      m[i] <- which(ranks[,i] == ranks[j,k])
    }
    left <- round(as.numeric(quantile(m, probs = c(0.1, 0.9))[1]))
    right <- round(as.numeric(quantile(m, probs = c(0.1, 0.9))[2]))
    n[j] <- j >= left & j <= right
  }
  if (sum(n) == 25) {
    print(c(k,(1946:1995)[k]))
  }
}

tt <- 32
m <- rep(0,50)
for (i in 1:50) {
  m[i] <- which(ranks[,i] == ranks[1,tt])
}
overlay <- data.frame(name = ranks[1,tt], ct = m, 
                      left = as.numeric(quantile(m, probs = c(0.1, 0.9))[1]), 
                      right = as.numeric(quantile(m, probs = c(0.1, 0.9))[2]),
                      rank = 1)
for (j in 2:25) {
  m <- rep(0,50)
  for (i in 1:50) {
    m[i] <- which(ranks[,i] == ranks[j,tt])
  }
  overlay <- rbind(overlay, data.frame(name = ranks[j,tt], ct = m, 
                                       left = as.numeric(quantile(m, probs = c(0.1, 0.9))[1]), 
                                       right = as.numeric(quantile(m, probs = c(0.1, 0.9))[2]), 
                                       rank = j))
}

t <- c(1,1)
for (j in 2:25) {
  m <- rep(0,50)
  for (i in 1:50) {
    m[i] <- which(ranks[,i] == ranks[j,tt])
  }
  left <- as.numeric(quantile(m, probs = c(0.1, 0.9))[1])
  right <- as.numeric(quantile(m, probs = c(0.1, 0.9))[2])
  t <- c(t, c(left, right))
}

comb = rep(0,50)
comb[(1:25)*2-1] <- ranks[1:25,tt]
comb[(1:25)*2] <- ranks[1:25,tt]
mm <- data.frame(name = comb, 
                 ct = t)
```

## Figure 4: Ranking stability analysis in the paper.

```{r}
library(ggridges)
ggplot() + stat_density_ridges(data = overlay, aes(y = reorder(name, -rank), x = ct), 
                               alpha = 0.5, quantile_lines = TRUE, 
                               quantiles = c(0.10, 0.90)) + 
  coord_cartesian(xlim = c(0,51)) + geom_line(data = mm, aes(x = ct, y = name)) + 
  geom_text(data = mm, aes(x = ct, y = name, label = round(ct)),
            vjust = 1, hjust = 1,
            show.legend = FALSE, size=4.5) + xlab((1946:1995)[tt]) + ylab("player")


```

# Ranking lists using different talent generating process

## Talent distribution follows folded normal distributon

### batters

```{r cache=TRUE}

library(VGAM)
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qfoldnorm(qbeta(u[j], j + npop[j] -n , n + 1 - j), mean = 0, sd = 1)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(PA >= thres)
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(PA < thres) %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

batters <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, age, PA, G, bWAR,pops)
colnames(batters)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters, cutoff, by = 'yearID')

batters <- batters %>% mutate(comp =  bWAR / G)

## batters bWAR

bat_thres <- function(component, component_name){
  ## stab means we add a small number to the largest value to avoid numerical stability problems. 
  ## stab depends on the scale of input values. In most cases, the default is 0.01. 
  ## cutoff means we select a certain percentage of systems that include maximal possible components in the tail
  ## rather than include k possible components in the tail based on the adjusted R adjusted square. 
  ## If the distance between the largest value and second largest value in the right tail is relatively large,
  ## adjusted R square may not be a good quantity to represent how well the fit is. 
  ## Then we usually choose the one sixth of all systems that their distances between the largest value and 
  ## second largest value are in the top one sixth. 
  
  if (component_name == 'bWAR') {
    cutoff <- 1.6e-2
    stab <- 0.01
  }
  if (component_name == 'fWAR') {
    cutoff <- 1.75e-2
    stab <- 0.01
  }
  if (component_name == 'HR') {
    cutoff <- 2.06e-2
    stab <- 0.01
  }
  if (component_name == 'BB') {
    cutoff <- 4.05e-2
    stab <- 0.01
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

batters_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "bWAR", year = yy, 
                           ystar = bat_thres(component = batters %>% filter(PA >= thres, yearID == yy) %>%
                                               select(comp), component_name = 'bWAR'))
})) %>% arrange(-WAR_talent)

career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pfoldnorm(x[j], mean = 0, sd = 1), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  min_year <- min(snippet$yearID)
  max_year <- max(snippet$yearID)
  end_year <- max_year - min_year + start_year
  end_year <- ifelse(end_year <= 2021, end_year, 2021)
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(start_year : end_year, function(xx){
    batters_int <- dataset %>% filter(yearID == xx, PA >= thres)
    
    target_snippet <- snippet %>% filter(yearID == (xx - start_year + min_year))
    yy <- sort(batters_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, target_snippet)
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    batters_int %>% mutate(ref_year = xx)
  }))
  
} 
foo <- batters_talent_bWAR
foo$playerID <- droplevels(as.factor(foo$playerID))

mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
    int <- career_talent(dataset = foo, component_name = 'bWAR', snippet = foo %>% filter(playerID == zz), 
                         start_year = ss)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_batters_1 <- merge(career_kAB, mapped_quan_b, 
                            by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                            by = c('ref_year'))
  
  mapped_batters_3 <- mapped_batters_2 %>% mutate(adj_bWAR = adj_comp * mapped_G)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_batters <- merge(mapped_batters_3, min_refbWAR, 
                          by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(PA < thres) %>% 
        mutate(adj_bWAR = (1 - mapped_PA/PA_thres) * bWAR + mapped_PA/PA_thres * (adj_bWAR))
      tt <- xx %>% filter(PA >= thres)
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_G = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
      
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR) %>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
  career_fold_b <- do.call(rbind, mclapply(split(smoothed_bWAR,f = droplevels(as.factor(smoothed_bWAR$playerID))), mc.cores = ncores, FUN = function(xx){
    data.frame(name = unique(xx$name), 
               playerID = unique(xx$playerID), 
               rookie_year = min(xx$yearID), 
               avg_bWAR = sum(xx$avg_bWAR), 
               bWAR = sum(xx$bWAR), ref_year = nrow(xx))
    })) %>% arrange(desc(avg_bWAR))
  rownames(career_fold_b) <- c()
```

### pitchers

```{r cache=TRUE}
pitchers <- read_csv("pitchers_all.csv") %>% select(yearID, bbID, name, teamID, IP, bWAR, pops)
pitchers <- pitchers %>% mutate(comp = bWAR / IP) 
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'

library(retrosheet)
rotation_bound <- as.data.frame(cbind(years, unlist(mclapply(years, mc.cores = ncores, function(yr){
  foo <- getRetrosheet(type = "game", year = yr)
  Tms <- unique(foo$HmTm)
  
  starter <- lapply(Tms, function(tm){
    bar <- foo %>% filter(VisTm == tm | HmTm == tm) %>% 
      select(VisTm, HmTm, VisStPchID, HmStPchID, VisTmGNum, HmTmGNum)
    t(apply(bar, 1, function(xx){
      y <- NULL
      if(xx[2] == tm){
        y <- xx[4]
      }
      else{
        y <- xx[3]
      }
    })) 
  })
  
  y <- unlist(lapply(starter, function(xx){
    unlist(lapply(1:length(xx), function(j){
      flag <- TRUE
      k <- 1
      if(j > 1){
        while(flag){
          flag <- length(xx[(j-k):j]) == length(unique(xx[(j-k):j]))
          if(!flag){
            break
          }
          else{
            k <- k + 1
          }
          if(k == j){
            break
          }
        }
      }
      k
    }))
  }))
  mean(y)
  
}))))

unique_team <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  c(xx, nrow(unique(pitchers %>% filter(yearID == xx) %>% select(teamID))))
}))

rotation_player <- data.frame(yearID = years, rotation = ceiling(rotation_bound[,2] * unique_team[,2]))

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')
pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}

talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'ERA') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- y[1] - (y[2] - y[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qfoldnorm(qbeta(u[j], j + npop[j] -n , n + 1 - j), mean = 1, sd = 1)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(full_time == 'Y')
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(full_time == 'N') %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

pit_thres <- function(component, component_name){
  if (component_name == 'ERA') {
    cutoff <- 0.47
    stab <- 0.2
  }
  if (component_name == 'bWAR_p') {
    cutoff <- 8e-3
    stab <- 0.01
  }
  if (component_name == 'fWAR_p') {
    cutoff <- 5.7e-3
    stab <- 0.01
  }
  if (component_name == 'SO') {
    cutoff <- 1.56
    stab <- 0.2
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

pitchers_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "bWAR_p", year = yy, 
                           ystar = pit_thres(component = pitchers %>% 
                                               filter(full_time =='Y', yearID == yy) %>%
                                               select(comp), component_name = 'bWAR_p'))
})) %>% arrange(-WAR_talent) 

mapped_quan_p <- read.csv('mapped_quan_p.csv')[,-1]
rotation_talent <- read.csv('rotation_talent_folded.csv')[,-1]

career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pfoldnorm(x[j], mean = 1, sd = 1), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  
  do.call(rbind, lapply(snippet$ref_year, function(xx){
    pitchers_int <- dataset %>% filter(yearID == xx, full_time == 'Y')
    
    target_snippet <- snippet %>% filter(ref_year == xx)
    yy <- sort(pitchers_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'ERA') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'bWAR_p'| component_name == 'fWAR_p') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(yy[1] - (yy[2] - yy[1]) < 0, 0, yy[1] - (yy[2] - yy[1]) )
    }
    ytilde[n+1] <- yy[n] + unique(pitchers_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    pitchers_int <- rbind(pitchers_int, target_snippet)
    pitchers_int$pops[nrow(pitchers_int)] <- pitchers_int$pops[1]
    pitchers_int <- pitchers_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    pitchers_int
  }))
} 

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_bWAR$playerID), function(xx){
    m <- pitchers_talent_bWAR %>% filter(playerID == xx) %>% 
      select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
    m
  }, mc.cores = ncores)) 
  
  foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))
  
  # get career adjustment on season by season basis  
  career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
    int <- career_talent(dataset = foo, component_name = 'bWAR_p', 
                         snippet = foo %>% filter(playerID == xx), start_year = yy)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% 
    mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                             by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_cutoff <- cutoff
  colnames(mapped_cutoff) <- c('IP_thres', 'ref_year')
  
  mapped_pitchers_2 <- merge(mapped_pitchers_1, mapped_cutoff, by = c('ref_year'))
  
  mapped_pitchers_3 <- mapped_pitchers_2 %>% mutate(adj_bWAR = adj_comp * mapped_IP)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_pitchers <- merge(mapped_pitchers_3, min_refbWAR, 
                           by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(full_time == 'N') %>% 
        mutate(adj_bWAR = (1 - mapped_IP/IP_thres) * bWAR + mapped_IP/IP_thres * (adj_bWAR))
      tt <- xx %>% filter(full_time == 'Y')
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_IP = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR)%>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
  career_fold_p <- do.call(rbind, mclapply(split(smoothed_bWAR,f = droplevels(as.factor(smoothed_bWAR$playerID))),mc.cores = ncores, FUN = function(xx){
    data.frame(name = unique(xx$name), 
               playerID = unique(xx$playerID), 
               rookie_year = min(xx$yearID), 
               avg_bWAR = sum(xx$avg_bWAR), 
               bWAR = sum(xx$bWAR), 
               span = nrow(xx))
    })) %>% arrange(desc(avg_bWAR))
  
  rownames(career_fold_p) <- c()
```

```{r}
m_b <- career_fold_b %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_p <- career_fold_p %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_fold <- rbind(m_b, m_p)

index <- which(m_fold$name == "Babe Ruth")
m_fold$avg_bWAR[index[1]] <- sum(m_fold$avg_bWAR[index])
index <- which(m_fold$name == "Shohei Ohtani")
m_fold$avg_bWAR[index[1]] <- sum(m_fold$avg_bWAR[index])

(m_fold %>% arrange(desc(avg_bWAR)))[1:25,]

```

## Talent distribution follows normal distributon

### batters

```{r cache=TRUE}
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qnorm(qbeta(u[j], j + npop[j] -n , n + 1 - j), mean = 0, sd = 1)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(PA >= thres)
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(PA < thres) %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

batters <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, age, PA, G, bWAR,pops)
colnames(batters)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters, cutoff, by = 'yearID')

batters <- batters %>% mutate(comp =  bWAR / G)

## batters bWAR

bat_thres <- function(component, component_name){
  ## stab means we add a small number to the largest value to avoid numerical stability problems. 
  ## stab depends on the scale of input values. In most cases, the default is 0.01. 
  ## cutoff means we select a certain percentage of systems that include maximal possible components in the tail
  ## rather than include k possible components in the tail based on the adjusted R adjusted square. 
  ## If the distance between the largest value and second largest value in the right tail is relatively large,
  ## adjusted R square may not be a good quantity to represent how well the fit is. 
  ## Then we usually choose the one sixth of all systems that their distances between the largest value and 
  ## second largest value are in the top one sixth. 
  
  if (component_name == 'bWAR') {
    cutoff <- 1.6e-2
    stab <- 0.01
  }
  if (component_name == 'fWAR') {
    cutoff <- 1.75e-2
    stab <- 0.01
  }
  if (component_name == 'HR') {
    cutoff <- 2.06e-2
    stab <- 0.01
  }
  if (component_name == 'BB') {
    cutoff <- 4.05e-2
    stab <- 0.01
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

batters_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "bWAR", year = yy, 
                           ystar = bat_thres(component = batters %>% filter(PA >= thres, yearID == yy) %>%
                                               select(comp), component_name = 'bWAR'))
})) %>% arrange(-WAR_talent)

career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pnorm(x[j], mean = 0, sd = 1), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  min_year <- min(snippet$yearID)
  max_year <- max(snippet$yearID)
  end_year <- max_year - min_year + start_year
  end_year <- ifelse(end_year <= 2021, end_year, 2021)
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(start_year : end_year, function(xx){
    batters_int <- dataset %>% filter(yearID == xx, PA >= thres)
    
    target_snippet <- snippet %>% filter(yearID == (xx - start_year + min_year))
    yy <- sort(batters_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, target_snippet)
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    batters_int %>% mutate(ref_year = xx)
  }))
  
} 
foo <- batters_talent_bWAR
foo$playerID <- droplevels(as.factor(foo$playerID))

mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
    int <- career_talent(dataset = foo, component_name = 'bWAR', 
                         snippet = foo %>% filter(playerID == zz), 
                         start_year = ss)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_batters_1 <- merge(career_kAB, mapped_quan_b, 
                            by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                            by = c('ref_year'))
  
  mapped_batters_3 <- mapped_batters_2 %>% mutate(adj_bWAR = adj_comp * mapped_G)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_batters <- merge(mapped_batters_3, min_refbWAR, 
                          by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(PA < thres) %>% 
        mutate(adj_bWAR = (1 - mapped_PA/PA_thres) * bWAR + mapped_PA/PA_thres * (adj_bWAR))
      tt <- xx %>% filter(PA >= thres)
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_G = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
      
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR) %>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
  career_normal_b <- do.call(rbind, mclapply(split(smoothed_bWAR,f = droplevels(as.factor(smoothed_bWAR$playerID))), 
                                         mc.cores = ncores, FUN = function(xx){
                                           data.frame(name = unique(xx$name), 
                                                      playerID = unique(xx$playerID), 
                                                      rookie_year = min(xx$yearID), 
                                                      avg_bWAR = sum(xx$avg_bWAR), 
                                                      bWAR = sum(xx$bWAR), ref_year = nrow(xx))
                                         })) %>% arrange(desc(avg_bWAR))
  rownames(career_normal_b) <- c()
```

### pitchers

```{r cache=TRUE}

pitchers <- read_csv("pitchers_all.csv") %>% select(yearID, bbID, name, teamID, IP, bWAR, pops)
pitchers <- pitchers %>% mutate(comp = bWAR / IP) 
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'

library(retrosheet)
rotation_bound <- as.data.frame(cbind(years, unlist(mclapply(years, mc.cores = ncores, function(yr){
  foo <- getRetrosheet(type = "game", year = yr)
  Tms <- unique(foo$HmTm)
  
  starter <- lapply(Tms, function(tm){
    bar <- foo %>% filter(VisTm == tm | HmTm == tm) %>% 
      select(VisTm, HmTm, VisStPchID, HmStPchID, VisTmGNum, HmTmGNum)
    t(apply(bar, 1, function(xx){
      y <- NULL
      if(xx[2] == tm){
        y <- xx[4]
      }
      else{
        y <- xx[3]
      }
    })) 
  })
  
  y <- unlist(lapply(starter, function(xx){
    unlist(lapply(1:length(xx), function(j){
      flag <- TRUE
      k <- 1
      if(j > 1){
        while(flag){
          flag <- length(xx[(j-k):j]) == length(unique(xx[(j-k):j]))
          if(!flag){
            break
          }
          else{
            k <- k + 1
          }
          if(k == j){
            break
          }
        }
      }
      k
    }))
  }))
  mean(y)
  
}))))

unique_team <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  c(xx, nrow(unique(pitchers %>% filter(yearID == xx) %>% select(teamID))))
}))

rotation_player <- data.frame(yearID = years, rotation = ceiling(rotation_bound[,2] * unique_team[,2]))

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')
pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}

talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 1.16){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'ERA') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- y[1] - (y[2] - y[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 1.16, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qnorm(qbeta(u[j], j + npop[j] -n , n + 1 - j), mean = 0, sd = 1)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(full_time == 'Y')
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(full_time == 'N') %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

pit_thres <- function(component, component_name){
  if (component_name == 'ERA') {
    cutoff <- 0.47
    stab <- 0.2
  }
  if (component_name == 'bWAR_p') {
    cutoff <- 8e-3
    stab <- 0.01
  }
  if (component_name == 'fWAR_p') {
    cutoff <- 5.7e-3
    stab <- 0.01
  }
  if (component_name == 'SO') {
    cutoff <- 1.56
    stab <- 0.2
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

pitchers_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "bWAR_p", year = yy, ystar = pit_thres(component = pitchers %>% filter(full_time =='Y', yearID == yy) %>% select(comp), component_name = 'bWAR_p'))
})) %>% arrange(-WAR_talent) 

mapped_quan_p <- read.csv('mapped_quan_p.csv')[,-1]
rotation_talent <- read.csv('rotation_talent_normal.csv')[,-1]
career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 1.16, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pnorm(x[j], mean = 0, sd = 1), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  
  do.call(rbind, lapply(snippet$ref_year, function(xx){
    pitchers_int <- dataset %>% filter(yearID == xx, full_time == 'Y')
    
    target_snippet <- snippet %>% filter(ref_year == xx)
    yy <- sort(pitchers_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'ERA') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'bWAR_p'| component_name == 'fWAR_p') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(yy[1] - (yy[2] - yy[1]) < 0, 0, yy[1] - (yy[2] - yy[1]) )
    }
    ytilde[n+1] <- yy[n] + unique(pitchers_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    pitchers_int <- rbind(pitchers_int, target_snippet)
    pitchers_int$pops[nrow(pitchers_int)] <- pitchers_int$pops[1]
    pitchers_int <- pitchers_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    pitchers_int
  }))
} 

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_bWAR$playerID), function(xx){
    m <- pitchers_talent_bWAR %>% filter(playerID == xx) %>% 
      select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
    m
  }, mc.cores = ncores)) 
  
  foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))
  
  # get career adjustment on season by season basis  
  career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
    int <- career_talent(dataset = foo, component_name = 'bWAR_p', 
                         snippet = foo %>% filter(playerID == xx), start_year = yy)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% 
    mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                             by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_cutoff <- cutoff
  colnames(mapped_cutoff) <- c('IP_thres', 'ref_year')
  
  mapped_pitchers_2 <- merge(mapped_pitchers_1, mapped_cutoff, by = c('ref_year'))
  
  mapped_pitchers_3 <- mapped_pitchers_2 %>% mutate(adj_bWAR = adj_comp * mapped_IP)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_pitchers <- merge(mapped_pitchers_3, min_refbWAR, 
                           by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(full_time == 'N') %>% 
        mutate(adj_bWAR = (1 - mapped_IP/IP_thres) * bWAR + mapped_IP/IP_thres * (adj_bWAR))
      tt <- xx %>% filter(full_time == 'Y')
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_IP = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR)%>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
career_normal_p <- do.call(rbind, mclapply(split(smoothed_bWAR, f = droplevels(as.factor(smoothed_bWAR$playerID))), mc.cores = ncores, FUN = function(xx){
    data.frame(name = unique(xx$name), 
               playerID = unique(xx$playerID),
               rookie_year = min(xx$yearID), 
               avg_bWAR = sum(xx$avg_bWAR), 
               bWAR = sum(xx$bWAR), 
               span = nrow(xx))
    })) %>% arrange(desc(avg_bWAR))
  
  rownames(career_normal_p) <- c()

```

```{r}
m_b <- career_normal_b %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_p <- career_normal_p %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_normal <- rbind(m_b, m_p)

index <- which(m_normal$name == "Babe Ruth")
m_normal$avg_bWAR[index[1]] <- sum(m_normal$avg_bWAR[index])
index <- which(m_normal$name == "Shohei Ohtani")
m_normal$avg_bWAR[index[1]] <- sum(m_normal$avg_bWAR[index])

(m_normal %>% arrange(desc(avg_bWAR)))[1:25,]
```

## Talent distribution follows Pareto distributon with alpha = 3

### batters

```{r cache=TRUE}
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 3){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 3, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qPareto(qbeta(u[j], j + npop[j] -n , n + 1 - j), t = 1, alpha = alpha)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(PA >= thres)
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(PA < thres) %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

batters <- read_csv("batters_all.csv") %>% select(yearID, bbID, name, age, PA, G, bWAR,pops)
colnames(batters)[2] <- 'playerID'

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- batters %>% filter(yearID == xx) %>% filter(PA >= 75)
  data.frame(thres = median(m$PA), yearID = xx)
}))

batters <- merge(batters, cutoff, by = 'yearID')

batters <- batters %>% mutate(comp =  bWAR / G)

## batters bWAR

bat_thres <- function(component, component_name){
  ## stab means we add a small number to the largest value to avoid numerical stability problems. 
  ## stab depends on the scale of input values. In most cases, the default is 0.01. 
  ## cutoff means we select a certain percentage of systems that include maximal possible components in the tail
  ## rather than include k possible components in the tail based on the adjusted R adjusted square. 
  ## If the distance between the largest value and second largest value in the right tail is relatively large,
  ## adjusted R square may not be a good quantity to represent how well the fit is. 
  ## Then we usually choose the one sixth of all systems that their distances between the largest value and 
  ## second largest value are in the top one sixth. 
  
  if (component_name == 'bWAR') {
    cutoff <- 1.6e-2
    stab <- 0.01
  }
  if (component_name == 'fWAR') {
    cutoff <- 1.75e-2
    stab <- 0.01
  }
  if (component_name == 'HR') {
    cutoff <- 2.06e-2
    stab <- 0.01
  }
  if (component_name == 'BB') {
    cutoff <- 4.05e-2
    stab <- 0.01
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

batters_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = batters, component_name = "bWAR", year = yy, ystar = bat_thres(component = batters %>% filter(PA >= thres, yearID == yy) %>% select(comp), component_name = 'bWAR'))
})) %>% arrange(-WAR_talent)

career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 3, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  min_year <- min(snippet$yearID)
  max_year <- max(snippet$yearID)
  end_year <- max_year - min_year + start_year
  end_year <- ifelse(end_year <= 2021, end_year, 2021)
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  do.call(rbind, lapply(start_year : end_year, function(xx){
    batters_int <- dataset %>% filter(yearID == xx, PA >= thres)
    
    target_snippet <- snippet %>% filter(yearID == (xx - start_year + min_year))
    yy <- sort(batters_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'bWAR' | component_name == 'fWAR') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'HR' | component_name == 'BB') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- 0
    }
    ytilde[n+1] <- yy[n] + unique(batters_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    batters_int <- rbind(batters_int, target_snippet)
    batters_int$pops[nrow(batters_int)] <- batters_int$pops[1]
    batters_int <- batters_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    batters_int %>% mutate(ref_year = xx)
  }))
  
} 
foo <- batters_talent_bWAR
foo$playerID <- droplevels(as.factor(foo$playerID))

mapped_quan_b <- read.csv('mapped_quan_b.csv')[,-1]

mapped_cutoff <- cutoff
colnames(mapped_cutoff) <- c('PA_thres', 'ref_year')

ss = 1977

career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(zz){
    int <- career_talent(dataset = foo, component_name = 'bWAR', 
                         snippet = foo %>% filter(playerID == zz), 
                         start_year = ss)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_batters_1 <- merge(career_kAB, mapped_quan_b, 
                            by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_batters_2 <- merge(mapped_batters_1, mapped_cutoff, 
                            by = c('ref_year'))
  
  mapped_batters_3 <- mapped_batters_2 %>% mutate(adj_bWAR = adj_comp * mapped_G)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_batters_3 %>% filter(yearID == zz, PA >= thres)
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_batters <- merge(mapped_batters_3, min_refbWAR, 
                          by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_batters, f = droplevels(as.factor(mapped_batters$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(PA < thres) %>% 
        mutate(adj_bWAR = (1 - mapped_PA/PA_thres) * bWAR + mapped_PA/PA_thres * (adj_bWAR))
      tt <- xx %>% filter(PA >= thres)
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_G = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
      
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR) %>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
career_pareto_b <- do.call(rbind, mclapply(split(smoothed_bWAR,f = droplevels(as.factor(smoothed_bWAR$playerID))), mc.cores = ncores, FUN = function(xx){
    data.frame(name = unique(xx$name), 
               playerID = unique(xx$playerID), 
               rookie_year = min(xx$yearID), 
               avg_bWAR = sum(xx$avg_bWAR), 
               bWAR = sum(xx$bWAR), ref_year = nrow(xx))
    })) %>% arrange(desc(avg_bWAR))
  rownames(career_pareto_b) <- c()
```

### pitchers

```{r cache=TRUE}
pitchers <- read_csv("pitchers_all.csv") %>% select(yearID, bbID, name, teamID, IP, bWAR, pops)
pitchers <- pitchers %>% mutate(comp = bWAR / IP) 
pitchers$comp[is.na(pitchers$comp)] = 0
colnames(pitchers)[2] <- 'playerID'
Ftilde <- function(y, t, ystar, component_name){
  y <- sort(y)
  n <- length(y)
  ytilde <- rep(0, n + 1)
  
  if (component_name == 'bWAR' | component_name == 'fWAR' | component_name == 'ERA') {
    ytilde[1] <- y[1] - (y[2] - y[1])
  }
  if (component_name == 'HR'| component_name == 'BB') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- 0
  }
  if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- y[1] - (y[2] - y[1])/10
  }
  if (component_name == 'SO') {
    # since the minimal HR is greater or equal to 0.
    ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
  }
  
  ytilde[n+1] <- y[n] + ystar
  ytilde[2:n] <- unlist(lapply(2:n, function(j){
    (y[j]+y[j-1])/2 
  }))
  
  if (t >= ytilde[n+1]) {
    1 - 0.1^7
  } else if (t <= ytilde[1]) {
    0
  } else {
    j <- length(which(ytilde < t))
    (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
  }
  
}

library(retrosheet)
rotation_bound <- as.data.frame(cbind(years, unlist(mclapply(years, mc.cores = ncores, function(yr){
  foo <- getRetrosheet(type = "game", year = yr)
  Tms <- unique(foo$HmTm)
  
  starter <- lapply(Tms, function(tm){
    bar <- foo %>% filter(VisTm == tm | HmTm == tm) %>% 
      select(VisTm, HmTm, VisStPchID, HmStPchID, VisTmGNum, HmTmGNum)
    t(apply(bar, 1, function(xx){
      y <- NULL
      if(xx[2] == tm){
        y <- xx[4]
      }
      else{
        y <- xx[3]
      }
    })) 
  })
  
  y <- unlist(lapply(starter, function(xx){
    unlist(lapply(1:length(xx), function(j){
      flag <- TRUE
      k <- 1
      if(j > 1){
        while(flag){
          flag <- length(xx[(j-k):j]) == length(unique(xx[(j-k):j]))
          if(!flag){
            break
          }
          else{
            k <- k + 1
          }
          if(k == j){
            break
          }
        }
      }
      k
    }))
  }))
  mean(y)
  
}))))

unique_team <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  c(xx, nrow(unique(pitchers %>% filter(yearID == xx) %>% select(teamID))))
}))

rotation_player <- data.frame(yearID = years, rotation = ceiling(rotation_bound[,2] * unique_team[,2]))

cutoff <- do.call(rbind, mclapply(years, mc.cores = ncores, FUN = function(xx){
  m <- pitchers %>% filter(yearID == xx) %>% arrange(-IP)
  index <- rotation_player$rotation[rotation_player$yearID == xx]
  data.frame(thres = (m$IP[index]), yearID = xx)
}))

pitchers <- merge(pitchers, cutoff, by = 'yearID')
pitchers <- pitchers %>% mutate(full_time = ifelse(IP >= thres, 'Y', 'N'))
talent_computing_nonpara <- function(dataset, component_name, year, ystar, alpha = 3){
  # dataset should include the component name and corresponding npop 
  Ftilde <- function(y, t, ystar, component_name){
    y <- sort(y)
    n <- length(y)
    ytilde <- rep(0, n + 1)
    
    if (component_name == 'ERA') {
      ytilde[1] <- y[1] - (y[2] - y[1])
    }
    if (component_name == 'bWAR_p' | component_name == 'fWAR_p') {
      # since the minimal HR is greater or equal to 0.
      ytilde[1] <- y[1] - (y[2] - y[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(y[1] - (y[2] - y[1]) < 0, 0, y[1] - (y[2] - y[1]) )
    }
    
    ytilde[n+1] <- y[n] + ystar
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (y[j]+y[j-1])/2 
    }))
    
    if (t >= ytilde[n+1]) {
      1 - 0.1^7
    } else if (t <= ytilde[1]) {
      0
    } else {
      j <- length(which(ytilde < t))
      (j - 1) / n + (t - ytilde[j]) / (n*(ytilde[j+1] - ytilde[j]))
    }
    
  }
  
  Aptitude_nonpara <- function(p, alpha = 3, npop){
    
    # converts order stats to their percentiles
    order_pbino <- function(p = 0, k = 1, n = 1e4){
      pbinom(k - 1, prob = p, size = n, lower.tail = FALSE)
    }
    
    # converts a vector of order stats 
    # to their percentiles. This vector should be the entire 
    # sample sorted in increasing order
    p <- sort(p) # just in case
    n <- length(p)
    u = unlist(lapply(1:n, function(j){
      order_pbino(p[j], k = j, n = n)
    }))
    
    # transforms percentiles from order stats (in increasing order)
    # to Pareto values corresponding to the general population 
    # of a greater than or equal to size
    # default alpha is that of the Pareto principle 80-20
    n <- length(u)
    if(length(npop) == 1) npop <- rep(npop, n)
    unlist(lapply(1:n, function(j){
      qPareto(qbeta(u[j], j + npop[j] -n , n + 1 - j), t = 1, alpha = alpha)
    }))
  }
  
  foo <- dataset %>% filter(yearID == year) %>% 
    arrange(comp) 
  bar <- foo %>% filter(full_time == 'Y')
  full_comp <- bar$comp
  ## batter WAR talent
  bar <- bar %>% 
    mutate(WAR_talent = 
             Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
               Ftilde(y = comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops))
  
  max_WAR_talent <- max(bar$WAR_talent) - 1
  range <- which(!(foo$playerID %in% bar$playerID))
  
  ## using the distribution from full time players
  bar <- rbind(bar, do.call(rbind, lapply(range, function(j){
    rbind(bar %>% dplyr::select(-WAR_talent), foo[j, ]) %>% arrange(comp) %>%
      mutate(WAR_talent = Aptitude_nonpara(p = unlist(lapply(comp, function(xx) 
        Ftilde(y = full_comp, t = xx, ystar = ystar, component_name = component_name))), npop = pops)) %>%
      filter(full_time == 'N') %>% 
      mutate(WAR_talent = ifelse(WAR_talent > max_WAR_talent+1, max_WAR_talent, WAR_talent))
  })))
  bar %>% mutate(ystar = ystar)
}

pit_thres <- function(component, component_name){
  if (component_name == 'ERA') {
    cutoff <- 0.47
    stab <- 0.2
  }
  if (component_name == 'bWAR_p') {
    cutoff <- 8e-3
    stab <- 0.01
  }
  if (component_name == 'fWAR_p') {
    cutoff <- 5.7e-3
    stab <- 0.01
  }
  if (component_name == 'SO') {
    cutoff <- 1.56
    stab <- 0.2
  }
  # obtain initial quantities for linear approximation
  Y <- sort(as.matrix(component))
  n <- length(Y)
  Y[n] <- Y[n] + stab # for stability
  pi <- 1 - (n:1 - 1/3)/(n + 1/3)
  W <- log(pi/(1-pi))
  K1 = max(6, floor(1.3*sqrt(n))); K2 = 2*floor(log10(n)*sqrt(n))
  k <- 6
  
  # use arguments from Scholz section 3 for estimating k
  #
  # this argument is based on model fit and not longest stretch of 
  # contiguous I0
  ind <- NULL
  try({
    k_selector <- do.call(rbind, lapply(6:K2, function(k){
      
      Ytil <- Y - median(Y)
      Ztil <- tail(Ytil, k)
      M1k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1]) )
      M2k <- 1/(k-1) * sum( log(Ztil[2:k]/Ztil[1])^2 )
      ck <- M1k + 1 - 0.5*(1 - M1k^2/M2k)^{-1}
      fck <- ((-n*log(pi))^{-ck} - 1)/ck
      
      Sigma <- matrix(0, k, k)
      for(i in 1:k){
        for(j in 1:i){
          Sigma[i,j] <- i^{-ck-1} * j^{-ck}
        } 
      }
      for(j in 1:k){
        for(i in 1:(j-1)){
          Sigma[i,j] <- j^{-ck-1} * i^{-ck}
        } 
      }
      
      rotate <- function(x) t(apply(x, 2, rev))
      Sigma <- rotate(rotate(Sigma))
      Sigma.inv <-  solve(Sigma)
      eig <- eigen(Sigma.inv)
      C <- eig$vec %*% diag(sqrt(eig$val)) %*% t(eig$vec)
      Zk <- C %*% tail(Y, k)
      Xk <- cbind(1, tail(fck, k))
      Wk <-  C %*% Xk
      # try linear and quadratic model
      m1 <- lm(tail(Y, k) ~ tail(fck, k))
      m2 <- lm(tail(Y, k) ~ tail(fck, k) + I(tail(fck, k)^2))
      m3 <- lm(Zk ~ -1 + Wk)
      delta.sq <- summary(m3)$sigma^2
      Tk <- coef(m3)[2] / summary(m3)$sigma
      
      kappa.sq <- solve(crossprod(Wk))[2,2]
      kappa <- sqrt(kappa.sq)
      I0 <- c(kappa * qt(0.25, df = k - 2, ncp = 1/kappa),
              kappa * qt(0.75, df = k - 2, ncp = 1/kappa))
      I1 <- c(kappa * qt(0.05, df = k - 2, ncp = 1/kappa), 
              kappa * qt(0.95, df = k - 2, ncp = 1/kappa))
      I0int <- ifelse(I0[1] <= Tk && Tk <= I0[2], 1, 0)
      I1int <- ifelse(I1[1] <= Tk && Tk <= I1[2], 1, 0)
      c(k, Tk, I0int, I1int, summary(m1)$adj.r.squared, 
        summary(m2)$adj.r.squared)
      
    }))
    
    #k <- k_selector[max(which(k_selector[, 3] == 1)), 1]
    #k <- k_selector[which.max(k_selector[, 5]), 1]
    k_selector <- as.data.frame(k_selector)
    colnames(k_selector) <- c("k", "Tk", "I0", "I1", "R.sq", "Rquad.sq")
    k_selector_I0 <- k_selector %>% filter(I0 == 1)
    a <- which.max(k_selector_I0$R.sq)
    b <- which.max(k_selector_I0$Rquad.sq)
    ind <- which.max(c(k_selector_I0[a, ]$R.sq, 
                       k_selector_I0[b, ]$Rquad.sq))
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > cutoff){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    
  }, silent = TRUE)
  
  if(length(k) == 0) k <- round(mean(K1,K2))
  if(is.na(k)) k <- round(mean(K1,K2))
  if(k == 0) k <- round(mean(K1,K2))
  if(k >= n) k <- K2
  
  
  # find probability value using linear tail behavior
  Z <- tail(Y, k)
  m1 <- lm(tail(Y, k) ~ tail(pi, k))
  beta <- m1$coefficients
  ystar <- ub <- 0
  f <- function(x) beta[1] + beta[2] * x - max(Y)
  #delta <- beta[2]
  try({
    foo <- uniroot(f, c(0.0001, 5), tol = 1e-10)
    ub <- foo$root        
  })
  
  # find probability value using logistic tail behavior
  if(ub >= 1){
    m1 <- lm(tail(Y,k) ~ tail(W, k))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) - max(Y)
    try({
      foo <- uniroot(f, c(0.000001, 0.999999), tol = 1e-10)
      ub <- foo$root        
    })  
  }
  
  # if possible, find ystar by tying logistic behavior argument to 
  # our Ftilde function
  if(ub >= Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar <- bar$root
    })
  }
  
  # if the above is not possible, try a similar approach for different 
  # suitable values of k. 
  #
  # The above fails because ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name) 
  # suggesting that the largest achiever is performaing much worse than 
  # expected. Thus ystar should be "large". A default large value will 
  # be ystar = 6 (altered to be log(1 + 6) for stability). This will 
  # be used when all else fails.
  flag <- NULL
  if(ub < Ftilde(y = Y, t = max(Y), ystar = 10, component_name = component_name)){
    
    # first try for largest suitable k as dictated by Scholz Section 3
    k <- max(k_selector_I0$k) 
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root
    }, silent = TRUE)
    while(class(flag) == "try-error"){
      k <- k - 1
      # method fails; use ystar = 4
      if(k < 6){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) +
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root
      }, silent = TRUE)
    }
    
    ystar_1 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_1 <- bar$root    	
    }, silent = TRUE)
    if(length(ystar_1) == 0) ystar_1 <- 6
    
    
    # now try for smallest suitable k as dictated by Scholz Section 3
    k <- min(k_selector_I0$k)
    if(length(k) == 0) k <- 6
    m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)  
    while(class(flag) == "try-error"){
      k <- k + 1
      # method fails; use ystar = 4
      if(k > max(k_selector_I0$k)){
        ystar <- 6
        break
      }
      m1 <- lm(tail(Y,k) ~ tail(W, k) + I(tail(W, k)^2))
      beta <- m1$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Y)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)  
    }
    
    ystar_2 <- NULL
    try({
      g <- function(ystar) ub - Ftilde(y = Y, t = max(Y), ystar = ystar, component_name = component_name)
      bar <- uniroot(g, c(0, 10), tol = 1e-10)
      ystar_2 <- bar$root			
    }, silent = TRUE)
    if(length(ystar_2) == 0) ystar_2 <- 6
    
    # take ystar as the average of the lowest working k and 
    # largest working k
    ystar <- mean(c(ystar_1, ystar_2))
    
  }
  
  # if changing k does not work, then try throwing out extreme 
  # observations and computing ystar for the reduced sample (Ytil)
  #
  # then compute ystar = max(Y) - max(Ytil) + ystar*
  #
  # where ystar* is computed with respect to Ytil
  if(ystar == 6){
    k <- k_selector_I0[c(a,b)[ind] , 1]
    if(diff(Y)[n-1] > 2){ 
      k <- max(k_selector_I0$k)
      if(k < 0) k <- K2
    }
    if(length(k) == 0) k <- round(mean(K1,K2))
    if(is.na(k)) k <- round(mean(K1,K2))
    if(k == 0) k <- round(mean(K1,K2))
    if(k >= n) k <- K2
    
    m1 <- lm(tail(Y, k) ~ tail(W, k) + I(tail(W, k)^2))
    beta <- m1$coefficients
    f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
      beta[3] * log(x/(1-x))^2 - max(Y)
    flag <- flag2 <- try({
      foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
      ub <- foo$root        
    }, silent = TRUE)
    
    n_lwr <- n 
    Ytil <- Y
    Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
    Wtil <- log(Xtil/(1-Xtil))
    while(class(flag) == "try-error" | class(flag2) == "try-error"){
      Ytil <- Ytil[-n_lwr]
      if(any(tail(Ytil, k) < 0)){
        ystar <- 6
        break
      }
      n_lwr <- n_lwr - 1
      Xtil <- 1 - (n_lwr:1 - 1/3)/(n_lwr + 1/3)
      Wtil <- log(Xtil/(1-Xtil))
      m2 <- lm(tail(Ytil, k) ~ tail(Wtil, k) + I(tail(Wtil, k)^2))
      beta <- m2$coefficients
      f <- function(x) beta[1] + beta[2] * log(x/(1-x)) + 
        beta[3] * log(x/(1-x))^2 - max(Ytil)
      flag <- try({
        foo <- uniroot(f, c(0.0001, 0.9999), tol = 1e-10)
        ub <- foo$root        
      }, silent = TRUE)
      flag2 <- try({
        g <- function(ystar) ub - Ftilde(y = Ytil, t = max(Ytil), ystar = ystar, component_name = component_name)
        bar <- uniroot(g, c(0, 10), tol = 1e-10)
        ystar <- bar$root
      }, silent = TRUE)
    }
    ystar <- max(Y) - Y[n_lwr] + ystar
    
  }
  
  # for stability
  ystar <- log(1 + ystar)
  ystar
  
}

pitchers_talent_bWAR <- do.call(rbind, mclapply(years, mc.cores = ncores, function(yy){
  talent_computing_nonpara(dataset = pitchers, component_name = "bWAR_p", year = yy,ystar = pit_thres(component = pitchers %>% filter(full_time =='Y', yearID == yy) %>%select(comp), component_name = 'bWAR_p'))
})) %>% arrange(-WAR_talent) 

mapped_quan_p <- read.csv('mapped_quan_p.csv')[,-1]
rotation_talent <- read.csv('rotation_talent_pareto.csv')[,-1]
career_talent <- function(dataset, component_name, snippet, start_year){
  Rev_Aptitude_nonpara <- function(x, ytilde, alpha = 3, npop){
    
    # transforms ordered Pareto values corresponding to 
    # the general population to percentiles from order stats 
    # (in increasing order)
    n <- length(x)
    if(length(npop) == 1) npop <- rep(npop, n)  
    u = unlist(lapply(1:n, function(j){
      pbeta(pPareto(x[j], t = 1, alpha = alpha), j + npop[j]-n, n + 1 - j)
    }))
    
    
    ## map the quantile to the a predicated sample value
    map_Y <- function(u, ytilde){
      n <- length(ytilde)-1
      seqence <- seq(0, 1, 1/n)
      pos <- findInterval(u, seqence)
      out <- (n*u -pos + 1) * (ytilde[(pos+1)] - ytilde[pos]) + ytilde[pos]
      return(out)
    }
    
    ## map the vector of quantiles to the predicated sample values 
    n <- length(u)
    a <- qbeta(u, shape1 = 1:n, shape2 = n:1)
    out <- sapply(1:n, function(x) map_Y(a[x], ytilde = ytilde))
    out
    
  }
  
  snippet <- snippet %>% mutate(playerID = paste(playerID, "_proj", sep = ""))
  
  do.call(rbind, lapply(snippet$ref_year, function(xx){
    pitchers_int <- dataset %>% filter(yearID == xx, full_time == 'Y')
    
    target_snippet <- snippet %>% filter(ref_year == xx)
    yy <- sort(pitchers_int$comp)
    n <- length(yy)
    ytilde <- rep(0, n + 1)
    if (component_name == 'ERA') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])
    }
    if (component_name == 'bWAR_p'| component_name == 'fWAR_p') {
      ytilde[1] <- yy[1] - (yy[2] - yy[1])/10
    }
    if (component_name == 'SO') {
      ytilde[1] <- ifelse(yy[1] - (yy[2] - yy[1]) < 0, 0, yy[1] - (yy[2] - yy[1]) )
    }
    ytilde[n+1] <- yy[n] + unique(pitchers_int$ystar)
    ytilde[2:n] <- unlist(lapply(2:n, function(j){
      (yy[j]+yy[j-1])/2 
    }))
    
    pitchers_int <- rbind(pitchers_int, target_snippet)
    pitchers_int$pops[nrow(pitchers_int)] <- pitchers_int$pops[1]
    pitchers_int <- pitchers_int %>% arrange(WAR_talent) %>% 
      mutate(adj_comp = Rev_Aptitude_nonpara(WAR_talent, ytilde = ytilde, npop = pops)) %>% 
      filter(playerID == unique(snippet$playerID))
    
    pitchers_int
  }))
} 

yy = 1977

foo_1 <- do.call(rbind, mclapply(unique(pitchers_talent_bWAR$playerID), function(xx){
    m <- pitchers_talent_bWAR %>% filter(playerID == xx) %>% 
      select(-WAR_talent) %>% mutate(ref_year = yearID + yy - min(yearID))
    m
  }, mc.cores = ncores)) 
  
  foo <- merge(foo_1, rotation_talent, by = c('yearID', 'playerID', 'ref_year'))
  
  # get career adjustment on season by season basis  
  career_kAB <- do.call(rbind, mclapply(unique(foo$playerID), function(xx){
    int <- career_talent(dataset = foo, component_name = 'bWAR_p', 
                         snippet = foo %>% filter(playerID == xx), start_year = yy)
    int
  }, mc.cores = ncores)) 
  
  career_kAB <- career_kAB %>% 
    mutate(playerID = gsub('.{5}$', '', playerID))
  
  mapped_pitchers_1 <- merge(career_kAB, mapped_quan_p, 
                             by = c('playerID', 'yearID', 'ref_year'))
  
  mapped_cutoff <- cutoff
  colnames(mapped_cutoff) <- c('IP_thres', 'ref_year')
  
  mapped_pitchers_2 <- merge(mapped_pitchers_1, mapped_cutoff, by = c('ref_year'))
  
  mapped_pitchers_3 <- mapped_pitchers_2 %>% mutate(adj_bWAR = adj_comp * mapped_IP)
  
  min_refbWAR <- do.call(rbind, mclapply(years, function(zz){
    m <- mapped_pitchers_2 %>% filter(yearID == zz, full_time == 'Y')
    data.frame(ref_year = zz, min_bWAR = min(m$bWAR))
  }, mc.cores = ncores)) 
  
  mapped_pitchers <- merge(mapped_pitchers_3, min_refbWAR, 
                           by = c('ref_year'))
  
  career_kAB_trim <- do.call(rbind, mclapply(
    split(mapped_pitchers, f = droplevels(as.factor(mapped_pitchers$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      zz <- xx %>% filter(full_time == 'N') %>% 
        mutate(adj_bWAR = (1 - mapped_IP/IP_thres) * bWAR + mapped_IP/IP_thres * (adj_bWAR))
      tt <- xx %>% filter(full_time == 'Y')
      xx <- rbind(zz, tt) %>% arrange(yearID)
      
      m1 <- xx %>% filter(adj_bWAR < min_bWAR) %>% 
        mutate(adj_bWAR = min_bWAR) %>%
        mutate(mapped_IP = adj_bWAR / adj_comp)
      m2 <- xx %>% filter(adj_bWAR >= min_bWAR)
      rbind(m1, m2) %>% arrange(yearID)
    }))
  
  career_kAB_trim_select <- career_kAB_trim %>% 
    select(name, playerID, yearID, adj_bWAR, bWAR, ref_year)
  
  library(splines)
  smoothed_bWAR <- do.call(rbind, mclapply(
    split(career_kAB_trim_select, 
          f = droplevels(as.factor(career_kAB_trim_select$playerID))), 
    mc.cores = ncores, FUN = function(xx){
      ## natural cubic spline
      ns_bWAR = lm(adj_bWAR ~ ns(yearID, df=6), data=xx)
      nn_bWAR <- predict(ns_bWAR, data.frame("yearID"= xx$yearID))
      xx %>% mutate(ss_adj_bWAR = nn_bWAR)%>% 
        mutate(avg_bWAR = (ss_adj_bWAR + adj_bWAR)/2)
    })) 
  
career_pareto_p <- do.call(rbind, mclapply(split(smoothed_bWAR, f = droplevels(as.factor(smoothed_bWAR$playerID))),mc.cores = ncores, FUN = function(xx){ 
  data.frame(name = unique(xx$name), 
             playerID = unique(xx$playerID), 
             rookie_year = min(xx$yearID), 
             avg_bWAR = sum(xx$avg_bWAR), 
             bWAR = sum(xx$bWAR), 
             span = nrow(xx))
  })) %>% arrange(desc(avg_bWAR))

rownames(career_pareto_p) <- c()
```

```{r}
m_b <- career_pareto_b %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_p <- career_pareto_p %>% 
  select(name, playerID, avg_bWAR, rookie_year)

m_pareto <- rbind(m_b, m_p)

index <- which(m_pareto$name == "Babe Ruth")
m_pareto$avg_bWAR[index[1]] <- sum(m_pareto$avg_bWAR[index])
index <- which(m_pareto$name == "Shohei Ohtani")
m_pareto$avg_bWAR[index[1]] <- sum(m_pareto$avg_bWAR[index])

(m_pareto %>% arrange(desc(avg_bWAR)))[1:25,]
```

## Table 7: Distribution sensitivity analysis in the Supplementary Materials.

```{r}

dist_combined <- cbind((m_normal %>% arrange(desc(avg_bWAR)))$name[1:25], (m_fold %>% arrange(desc(avg_bWAR)))$name[1:25], (m_pareto %>% arrange(desc(avg_bWAR)))$name[1:25], combined_bp[1:25, (32*2-1)])

colnames(dist_combined) <- c('standard normal', 'Folded normal (mu = 0, sigma = 1)', 'Pareto with alpha = 3', 'Pareto with alpha = 1.16')

rownames(dist_combined) <- c()


## matched name in top 10
dist_combined <- rbind(dist_combined, c(length(Reduce(intersect, list(dist_combined[1:10,1], dist_combined[1:10,4]))), length(Reduce(intersect, list(dist_combined[1:10,2], dist_combined[1:10,4]))), length(Reduce(intersect, list(dist_combined[1:10,3], dist_combined[1:10,4]))), length(Reduce(intersect, list(dist_combined[1:10,4], dist_combined[1:10,4])))))

## matched rank in top 10

dist_combined <- rbind(dist_combined, c(sum(dist_combined[1:10,1] == dist_combined[1:10,4]),sum(dist_combined[1:10,2] == dist_combined[1:10,4]), sum(dist_combined[1:10,3] == dist_combined[1:10,4]), sum(dist_combined[1:10,4] == dist_combined[1:10,4])))


## matched name in top 25
dist_combined <- rbind(dist_combined, c(length(Reduce(intersect, list(dist_combined[1:25,1], dist_combined[1:25,4]))), length(Reduce(intersect, list(dist_combined[1:25,2], dist_combined[1:25,4]))), length(Reduce(intersect, list(dist_combined[1:25,3], dist_combined[1:25,4]))), length(Reduce(intersect, list(dist_combined[1:25,4], dist_combined[1:25,4])))))

## matched rank in top 25

dist_combined <- rbind(dist_combined, c(sum(dist_combined[1:25,1] == dist_combined[1:25,4]),sum(dist_combined[1:25,2] == dist_combined[1:25,4]), sum(dist_combined[1:25,3] == dist_combined[1:25,4]), sum(dist_combined[1:25,4] == dist_combined[1:25,4])))

dist_combined

```

## Table 2: BA rankings from different sources in the paper.

```{r}
foo <- smoothed_AVG  %>% filter(AB >= 500)
foo$playerID <- droplevels(as.factor(foo$playerID))
bar <- split(foo, f = foo$playerID)
baz <- (do.call(rbind, mclapply(bar, mc.cores = ncores, function(xx){
  xx[which.max(xx$talent), ]
})) %>% arrange(-talent))

rookie_year <- master_batters %>% group_by(playerID) %>% 
  summarise(rookie_year = min(yearID))

m <- merge(baz, rookie_year, by = c('playerID'))

peak_fullhouse <- (m %>% filter(rookie_year <= 2011) %>% 
arrange(-talent))

batcar_year <- merge(career_batters, rookie_year, by = 'playerID')

career_fullhouse <- (batcar_year %>% 
                       filter(AB >= 3000, rookie_year <= 2011) %>% 
  arrange(desc(AVG)))

raw_career <- data.frame(name = c('Ty Cobb',  
'Rogers Hornsby', 'Shoeless Joe Jackson',  
"Lefty O'Doul", "Ed Delahanty", "Tris Speaker", 
"Bill Hamilton", "Ted Williams", "Dan Brouthers", "Babe Ruth", 
"Dave Orr", "Harry Heilmann","Pete Browning", "Willie Keeler", 
"Bill Terry", "Lou Gehrig", "George Sisler",  
"Jesse Burkett", "Tony Gwynn", "Nap Lajoie", "Jake Stenzel", 
"Riggs Stephenson", "Al Simmons", "Cap Anson", "John McGraw"
))

Schell_career <- data.frame(name = c("Tony Gwynn", "Ty Cobb", 
"Rod Carew", "Rogers Hornsby", "Stan Musial", "Nap Lajoie", 
"Shoeless Joe Jackson", "Honus Wagner", "Ted Williams", 
"Wade Boggs", "Pete Browning", "Tris Speaker", "Mike Piazza", 
"Dan Brouthers", "Tip O'Neill", "Kirby Puckett", "Tony Oliva", 
"Vladimir Guerrero", "Mike Donlin", "Willie Keeler", "Edgar Martinez", "Henry Aaron", "Derek Aaron", "Joe DiMaggio", "Babe Ruth"))

Era_bridging <- data.frame(name = c('Ty Cobb', 'Tony Gwynn', 'Ted Williams', 'Wade Boggs', 'Rod Carew', 'Shoeless Jos Jackson', 'Nap Lajoie', 'Stan Musial', 'Frank Thomas', 'Ed Delahanty', 'Tris Speaker', 'Rogers Hornsby', 'Hank Aaron', 'Alex Rodriguez', 'Pete Rose', 'Honus Wagner', 'Roberto Clements', 'George Brett', 'Don Mattingsly', 'Kirby Puckett', 'Mike Piazza', 'Eddie Collins', 'Edgar Martinez', 'Paul Molitor', 'Willie Mays'))

combined_AVG <- cbind(peak_fullhouse$name[1:25], career_fullhouse$name[1:25], Schell_career, Era_bridging, raw_career)

colnames(combined_AVG) <- c('Peak in Full House', 'Career in Full House', 'Schell Method', 'Era-bridging Method', 'Raw Career')

## pre-1950 in top 10
combined_AVG <- rbind(combined_AVG, c(2,1,7,6,10))

## pre-1950 in top 25
combined_AVG <- rbind(combined_AVG, c(5,2,15,10,24))

## proportion before 1950

combined_AVG <- rbind(combined_AVG, c(0.168, 0.168, 0.324, 0.213, 0.168))

## MLB eligible population range

combined_AVG <- rbind(combined_AVG, c('1871-2011', '1871-2011', '1876-1983', '1901-1996', '1871-2011'))

## chances of observing old era batters in top 10

combined_AVG <- rbind(combined_AVG, c(1 / (1 - pbinom(as.numeric(combined_AVG[26,1])-1, 10, as.numeric(combined_AVG[28,1]))), 1 / (1 - pbinom(as.numeric(combined_AVG[26,2])-1, 10, as.numeric(combined_AVG[28,2]))), 1 / (1 - pbinom(as.numeric(combined_AVG[26,3])-1, 10, as.numeric(combined_AVG[28,3]))), 1 / (1 - pbinom(as.numeric(combined_AVG[26,4])-1, 10, as.numeric(combined_AVG[28,4]))), 1 / (1 - pbinom(as.numeric(combined_AVG[26,5])-1, 10, as.numeric(combined_AVG[28,5])))))

## chances of observing old era batters in top 25

combined_AVG <- rbind(combined_AVG, c(1 / (1 - pbinom(as.numeric(combined_AVG[27,1])-1, 25, as.numeric(combined_AVG[28,1]))), 1 / (1 - pbinom(as.numeric(combined_AVG[27,2])-1, 25, as.numeric(combined_AVG[28,2]))), 1 / (1 - pbinom(as.numeric(combined_AVG[27,3])-1, 25, as.numeric(combined_AVG[28,3]))), 1 / (1 - pbinom(as.numeric(combined_AVG[27,4])-1, 25, as.numeric(combined_AVG[28,4]))), 1 / (1 - pbinom(as.numeric(combined_AVG[27,5])-1, 25, as.numeric(combined_AVG[28,5])))))

combined_AVG
```

## Table 3: HR rankings from different sources in the paper.

```{r}
bar <- batters_adjusted %>%
  filter(AB >= 500) %>% mutate(ABpHR = AB / HR) %>%
  group_by(playerID) %>%
  summarise(name = unique(name), ABpHR = min(ABpHR)) %>%
  arrange(ABpHR) %>% head(25)

career_fullhouse_HR_AB <- batcar_year %>% mutate(HR_AB = HR / AB) %>%
  filter(rookie_year <= 2005, AB >= 3000) %>% arrange(desc(HR_AB))

Era_bridging_HR <- data.frame(name = c('Mark McGwire', 'Juan Gonzalez', 'Babe Ruth', 'Dave Kingman', 'Mike Schmidt', 'Harmon Killebrew', 'Frank Thomas', 'Jose Canseco', 'Ron Kittle', 'Willie Stargell', 'Willie McCovey', 'Darryl Strawberry', 'Bo Jackson', 'Ted Williams', 'Ralph Kiner', 'Pat Seerey', 'Reggie Jackson', 'Ken Griffey', 'Albert Belle', 'Dick Allen', 'Barry Bonds', 'Dean Palmer', 'Hank Aaron', 'Jimmie Foxx', 'Mike Piazza'))

PPS_1 <- data.frame(name = c("Babe Ruth", "Mel Ott", "Lou Gehrig", 
"Jimmie Foxx", "Hank Aaron", "Rogers Hornsby", "Cy Williams", 
"Barry Bonds", "Willie Mays", "Ted Williams", "Reggie Jackson", 
"Mike Schmidt", "Frank Robinson", "Harmon Killebrew", "Gavvy Cravath", 
"Honus Wagner", "Willie McCovey", "Harry Stovey", "Ken Griffey Jr.", 
"Stan Musial", "Willie Stargell", "Eddie Murray", "Mark McGwire", 
"Mickey Mantle", "Al Simmons"))

raw_AB_HR <- data.frame(name = c("Mark McGwire", "Babe Ruth", 
"Barry Bonds", "Jim Thome", "Giancarlo Stanton", "Ralph Kiner", 
"Harmon Killebrew", "Sammy Sosa", "Ted Williams", "Manny Ramirez", 
"Mike Trout", "Adam Dunn", "Ryan Howard", "Juan Gonzalez", 
"Dave Kingman", "Russell Branyan", "Mickey Mantle", "Alex Rodriguez", 
"Jimmie Foxx", "Mike Schmidt", "Jose Canseco", "Albert Belle", 
"Khris Davis", "Ron Kittle", "Carlos Delgado"))

Schell_career_HR_AB <- data.frame(name = c("Babe Ruth", "Mark McGwire", 
"Ted Williams", "Barry Bonds", "Mike Schmidt", "Lou Gehrig", 
"Harmon Killebrew", "Jimmie Foxx", "Dave Kingman", "Reggic Jackson", 
"Bill Nicholson", "Mickey Mantle", "Ralph Kiner", "Joe DiMaggio", 
"Willie Stargell", "Hack Wilson", "Rogers Hornsby", "Darryl Strawberry", 
"Willie McCovey", "Glenn Davis", "Wally Berger", "Eddie Mathews", 
"Harry Stovey", "Frank Howard", "Mel Ott"))

Schell_peak_HR_AB <- c('Barry Bonds', 'Babe Ruth', 'Mark McGwire',
'Buck Frecman', 'Ed Delahanty', 'Tim Jordan','Willie Stargell', 
'Rogers Hornsby','Jim Thome','Dave Kingman','Roy Sievers',
'Jeff Bagwell','Ted Williams','Kevin Mitchell','Mike Schmidt','Lou Gehrig', 
'Fred Dunlap','Harry Stovey','Charlie Hickman', 'Bill Nicholson',
'Boog Powell', 'Joe DiMaggio', 'Eddie Mathews', 'Mickey Mantle', 
'Tris Speaker')

combined_HR <- cbind(bar$name[1:25], career_fullhouse_HR_AB$name[1:25], Era_bridging_HR, PPS_1, Schell_peak_HR_AB, Schell_career_HR_AB, raw_AB_HR)

colnames(combined_HR) <- c('Peak in Full House', 'Career in Full House', 'Era-bridging Method', 'PPS detrending method', 'Peak in Schell', 'Career in Schell', 'Raw AB per HR')

## pre-1950 in top 10
combined_HR <- rbind(combined_HR, c(3,1,1,7,5,4,3))

## pre-1950 in top 25
combined_HR <- rbind(combined_HR, c(4,4,5,12,13,12,4))

## proportion before 1950

combined_HR <- rbind(combined_HR, 
                c(0.138, 0.190, 0.213, 0.270, 0.176, 0.292, 0.190))

## MLB eligible population range

combined_HR <- rbind(combined_HR, c('1871-2021', '1871-2005', '1901-1996', '1871-1993', '1876-2003', '1876-1988', '1871-2005'))


## chances of observing old era players in top 10

combined_HR <- rbind(combined_HR, c(1 / (1 - pbinom(as.numeric(combined_HR[26,1])-1, 10, as.numeric(combined_HR[28,1]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,2])-1, 10, as.numeric(combined_HR[28,2]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,3])-1, 10, as.numeric(combined_HR[28,3]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,4])-1, 10, as.numeric(combined_HR[28,4]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,5])-1, 10, as.numeric(combined_HR[28,5]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,6])-1, 10, as.numeric(combined_HR[28,6]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,7])-1, 10, as.numeric(combined_HR[28,7])))))

## chances of observing old era players in top 25

combined_HR <- rbind(combined_HR, c(1 / (1 - pbinom(as.numeric(combined_HR[27,1])-1, 25, as.numeric(combined_HR[28,1]))), 1 / (1 - pbinom(as.numeric(combined_HR[27,2])-1, 25, as.numeric(combined_HR[28,2]))), 1 / (1 - pbinom(as.numeric(combined_HR[27,3])-1, 25, as.numeric(combined_HR[28,3]))), 1 / (1 - pbinom(as.numeric(combined_HR[27,4])-1, 25, as.numeric(combined_HR[28,4]))), 1 / (1 - pbinom(as.numeric(combined_HR[27,5])-1, 25, as.numeric(combined_HR[28,5]))), 1 / (1 - pbinom(as.numeric(combined_HR[27,6])-1, 25, as.numeric(combined_HR[28,6]))), 1 / (1 - pbinom(as.numeric(combined_HR[26,7])-1, 25, as.numeric(combined_HR[28,7])))))

combined_HR
```

## Table 1: OBP rankings from different sources in the Supplementary materials.

```{r}
OBP_fullhouse <- (batcar_year %>% 
                    filter(PA >= 3000, rookie_year <= 2011) %>%
  arrange(desc(OBP)))

raw_career_OBP <- data.frame(name = c("Ted Williams", "Babe Ruth", 
"John McGraw", "Billy Hamilton", "Oscar Charleston", "Lou Gehrig", 
"Barry Bonds", "Jud Wilson", "Bill Joyce", "Rogers Hornsby", 
"Ty Cobb", "Jimmie Foxx", "Tris Speaker", "Eddie Collins", 
"Ferris Fain", "Dan Brouthers", "Max Bishop", "Shoeless Joe Jackson", 
"Mickey Mantle", "Mickey Cochrane", "Frank Thomas", "Mike Trout", 
"Edgar Martinez", "Turkey Stearnes", "Stan Musial"))

Schell_career_OBP <- data.frame(name = c("Ted Williams", "Babe Ruth", 
"Rogers Hornsby", "Barry Bonds", "John McGraw", "Billy Hamilton", 
"Topsy Hartsel", "Mel Ott", "Roy Thomas", "Mickey Mantle", 
"Wade Boggs", "Frank Thomas", "Lou Gehrig", "Rickey Henderson", 
"Stan Musial", "Edgar Martinez", "Ty Cobb", "Dan Brouthers", 
"Tris Speaker", "Joe Cunningham", "George Gore", "Eddie Collins", 
"Ross Youngs", "Mike Hargrove", "Jeff Bagwell"))

combined_OBP <- cbind(OBP_fullhouse$name[1:25], Schell_career_OBP, raw_career_OBP)

colnames(combined_OBP) <- c('Career Full House', 'Schell Method', 'Raw Career')

## pre-1950 in top 10
combined_OBP <- rbind(combined_OBP, c(2,8,9))

## pre-1950 in top 25
combined_OBP <- rbind(combined_OBP, c(2,16,19))

## proportion before 1950

combined_OBP <- rbind(combined_OBP, c(0.168, 0.267, 0.168))

## MLB eligible population range

combined_OBP <- rbind(combined_OBP, c('1871-2011', '1876-1993', '1871-2011'))

## chances of observing old era batters in top 10

combined_OBP <- rbind(combined_OBP, c(1 / (1 - pbinom(as.numeric(combined_OBP[26,1])-1, 10, as.numeric(combined_OBP[28,1]))), 1 / (1 - pbinom(as.numeric(combined_OBP[26,2])-1, 10, as.numeric(combined_OBP[28,2]))), 1 / (1 - pbinom(as.numeric(combined_OBP[26,3])-1, 10, as.numeric(combined_OBP[28,3])))))

## chances of observing old era batters in top 25

combined_OBP <- rbind(combined_OBP, c(1 / (1 - pbinom(as.numeric(combined_OBP[27,1])-1, 25, as.numeric(combined_OBP[28,1]))), 1 / (1 - pbinom(as.numeric(combined_OBP[27,2])-1, 25, as.numeric(combined_OBP[28,2]))), 1 / (1 - pbinom(as.numeric(combined_OBP[27,3])-1, 25, as.numeric(combined_OBP[28,3])))))

combined_OBP

```

## Table 3: Top 25 BA, OBP and HR leaders in the Supplementary materials.

```{r}
rookie_year <- master_batters %>% group_by(playerID) %>% 
  summarise(rookie_year = min(yearID))
batcar_year <- merge(career_batters, rookie_year, by = 'playerID')
rownames(batcar_year) <- c()

zz_AVG <- (batcar_year %>% arrange(desc(AVG)) %>% 
             filter(AB >= 3000, rookie_year <= 2011) %>%
  select(name, AVG))[1:25,]
zz_OBP <- (batcar_year %>% arrange(desc(OBP)) %>% 
             filter(AB >= 3000, rookie_year <= 2011) %>%
         select(name, OBP))[1:25,]
zz_HR <- (batcar_year %>% arrange(desc(HR))  %>% 
            filter(rookie_year <= 2005) %>%
         select(name, HR))[1:25,]

AVG_OBP_HR <- cbind(zz_AVG, zz_OBP, zz_HR)
colnames(AVG_OBP_HR) <- c('name', 'BA', 'name', 'OBP', 'name', 'HR')

## pre-1950 in top 10
AVG_OBP_HR <- rbind(AVG_OBP_HR, c(1,NA, 2, NA, 1,NA))

## pre-1950 in top 25
AVG_OBP_HR <- rbind(AVG_OBP_HR, c(2,NA, 2, NA, 2,NA))

## proportion before 1950

AVG_OBP_HR <- rbind(AVG_OBP_HR, c(0.168,NA, 0.168,NA, 0.190,NA))

## MLB eligible population range

AVG_OBP_HR <- rbind(AVG_OBP_HR, c('1871-2011',NA, '1871-2011',NA, '1871-2005',NA))

## chances of observing old era batters in top 10

AVG_OBP_HR <- rbind(AVG_OBP_HR, c(1 / (1 - pbinom(as.numeric(AVG_OBP_HR[26,1])-1, 10, as.numeric(AVG_OBP_HR[28,1]))), NA, 1 / (1 - pbinom(as.numeric(AVG_OBP_HR[26,3])-1, 10, as.numeric(AVG_OBP_HR[28,3]))), NA, 1 / (1 - pbinom(as.numeric(AVG_OBP_HR[26,5])-1, 10, as.numeric(AVG_OBP_HR[28,5]))), NA))

## chances of observing old era batters in top 25

AVG_OBP_HR <- rbind(AVG_OBP_HR, c(1 / (1 - pbinom(as.numeric(AVG_OBP_HR[27,1])-1, 25, as.numeric(AVG_OBP_HR[28,1]))), NA, 1 / (1 - pbinom(as.numeric(AVG_OBP_HR[27,3])-1, 25, as.numeric(AVG_OBP_HR[28,3]))), NA, 1 / (1 - pbinom(as.numeric(AVG_OBP_HR[27,5])-1, 25, as.numeric(AVG_OBP_HR[28,5]))),NA))

AVG_OBP_HR

```

## Table 4: Top 25 bWAR and fWAR leaders for MLB batters in the Supplementary materials.

```{r}
zz_bWAR <- (batcar_year %>% arrange(desc(ebWAR))  %>%
              filter(rookie_year <= 2005) %>%
         select(name, ebWAR))[1:25,]
zz_fWAR <- (batcar_year %>% arrange(desc(efWAR))  %>%
              filter(rookie_year <= 2005) %>%
         select(name, efWAR))[1:25,]

ebWAR_efWAR_b <- cbind(zz_bWAR, zz_fWAR)
colnames(ebWAR_efWAR_b) <- c('name', 'ebWAR', 'name', 'efWAR')

## pre-1950 in top 10
ebWAR_efWAR_b <- rbind(ebWAR_efWAR_b, c(2,NA, 3, NA))

## pre-1950 in top 25
ebWAR_efWAR_b <- rbind(ebWAR_efWAR_b, c(5,NA, 6, NA))

## proportion before 1950

ebWAR_efWAR_b <- rbind(ebWAR_efWAR_b, c(0.190,NA, 0.190,NA))

## chances of observing old era batters in top 10

ebWAR_efWAR_b <- rbind(ebWAR_efWAR_b, c(1 / (1 - pbinom(as.numeric(ebWAR_efWAR_b[26,1])-1, 10, as.numeric(ebWAR_efWAR_b[28,1]))), NA, 1 / (1 - pbinom(as.numeric(ebWAR_efWAR_b[26,3])-1, 10, as.numeric(ebWAR_efWAR_b[28,3]))), NA))

## chances of observing old era batters in top 25

ebWAR_efWAR_b <- rbind(ebWAR_efWAR_b, c(1 / (1 - pbinom(as.numeric(ebWAR_efWAR_b[27,1])-1, 25, as.numeric(ebWAR_efWAR_b[28,1]))), NA, 1 / (1 - pbinom(as.numeric(ebWAR_efWAR_b[27,3])-1, 25, as.numeric(ebWAR_efWAR_b[28,3]))), NA))

ebWAR_efWAR_b

```

## Table 5: Top 25 IP, ERA, SO leaders in the Supplementary materials.

```{r}
rookie_year <- master_pitchers %>% group_by(playerID) %>% 
  summarise(rookie_year = min(yearID))
pitcar_year <- merge(career_pitchers, rookie_year, by = 'playerID')

zz_IP <- (pitcar_year %>% arrange(desc(IP)) %>%
            filter(rookie_year <= 2005) %>%
             select(name,IP))[1:25,]
zz_ERA <- (pitcar_year %>% arrange(ERA) %>% filter(IP >= 1500) %>% filter(rookie_year <= 2011) %>%
         select(name,ERA))[1:25,]
zz_K <- (pitcar_year %>% arrange(desc(K)) %>%
           filter(rookie_year <= 2005) %>%
         select(name, K))[1:25,]

IP_ERA_K <- cbind(zz_IP, zz_ERA, zz_K)
colnames(IP_ERA_K) <- c('name', 'IP', 'name', 'ERA', 'name', 'SO')

## pre-1950 in top 10
IP_ERA_K <- rbind(IP_ERA_K, c(3,NA, 0, NA, 1,NA))

## pre-1950 in top 25
IP_ERA_K <- rbind(IP_ERA_K, c(6,NA, 2, NA, 2,NA))

## proportion before 1950

IP_ERA_K <- rbind(IP_ERA_K, c(0.190,NA, 0.168,NA, 0.190,NA))

## MLB eligible population range

IP_ERA_K <- rbind(IP_ERA_K, c('1871-2005',NA, '1871-2011',NA, '1871-2005',NA))

## chances of observing old era pitchers in top 10

IP_ERA_K <- rbind(IP_ERA_K, c(1 / (1 - pbinom(as.numeric(IP_ERA_K[26,1])-1, 10, as.numeric(IP_ERA_K[28,1]))), NA, 1, NA, 1 / (1 - pbinom(as.numeric(IP_ERA_K[26,5])-1, 10, as.numeric(IP_ERA_K[28,5]))), NA))

## chances of observing old era pitchers in top 25

IP_ERA_K <- rbind(IP_ERA_K, c(1 / (1 - pbinom(as.numeric(IP_ERA_K[27,1])-1, 25, as.numeric(IP_ERA_K[28,1]))), NA, 1 / (1 - pbinom(as.numeric(IP_ERA_K[27,3])-1, 25, as.numeric(IP_ERA_K[28,3]))), NA, 1 / (1 - pbinom(as.numeric(IP_ERA_K[27,5])-1, 25, as.numeric(IP_ERA_K[28,5]))),NA))

IP_ERA_K
```

## Table 6: Top 25 bWAR and fWAR leaders for MLB batters in the Supplementary materials.

```{r}
zz_bWAR <- (pitcar_year %>% arrange(desc(ebWAR))  %>%
              filter(rookie_year <= 2005) %>%
         select(name, ebWAR))[1:25,]
zz_fWAR <- (pitcar_year %>% arrange(desc(efWAR))  %>%
              filter(rookie_year <= 2005) %>%
         select(name, efWAR))[1:25,]

ebWAR_efWAR_p <- cbind(zz_bWAR, zz_fWAR)
colnames(ebWAR_efWAR_p) <- c('name', 'ebWAR', 'name', 'efWAR')

## pre-1950 in top 10
ebWAR_efWAR_p <- rbind(ebWAR_efWAR_p, c(3,NA, 2, NA))

## pre-1950 in top 25
ebWAR_efWAR_p <- rbind(ebWAR_efWAR_p, c(4,NA, 4, NA))

## proportion before 1950

ebWAR_efWAR_p <- rbind(ebWAR_efWAR_p, c(0.190,NA, 0.190,NA))

## chances of observing old era pitchers in top 10

ebWAR_efWAR_p <- rbind(ebWAR_efWAR_p, c(1 / (1 - pbinom(as.numeric(ebWAR_efWAR_p[26,1])-1, 10, as.numeric(ebWAR_efWAR_p[28,1]))), NA, 1 / (1 - pbinom(as.numeric(ebWAR_efWAR_p[26,3])-1, 10, as.numeric(ebWAR_efWAR_p[28,3]))), NA))

## chances of observing old era pitchers in top 25

ebWAR_efWAR_p <- rbind(ebWAR_efWAR_p, c(1 / (1 - pbinom(as.numeric(ebWAR_efWAR_p[27,1])-1, 25, as.numeric(ebWAR_efWAR_p[28,1]))), NA, 1 / (1 - pbinom(as.numeric(ebWAR_efWAR_p[27,3])-1, 25, as.numeric(ebWAR_efWAR_p[28,3]))), NA))

ebWAR_efWAR_p

```
